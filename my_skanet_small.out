Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 8.Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 8.

Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 8.
Training in distributed mode with multiple processes, 1 GPU per process. Process 4, total 8.
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 8.
Training in distributed mode with multiple processes, 1 GPU per process. Process 6, total 8.
Training in distributed mode with multiple processes, 1 GPU per process. Process 5, total 8.
Training in distributed mode with multiple processes, 1 GPU per process. Process 7, total 8.
Model skanet_small created, param count:5535120
Data processing configuration for current model + dataset:
	input_size: (3, 256, 256)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.9
Using native Torch AMP. Training in mixed precision.
Using native Torch DistributedDataParallel.
Scheduled epochs: 60
Train: 0 [   0/1906 (  0%)]  Loss: 2.742 (2.74)  Time: 13.693s,   49.08/s  (13.693s,   49.08/s)  LR: 1.685e-06  Data: 1.706 (1.706)
Train: 0 [  50/1906 (  3%)]  Loss: 2.793 (2.77)  Time: 1.533s,  438.38/s  (1.764s,  380.97/s)  LR: 1.685e-06  Data: 0.013 (0.048)
Train: 0 [ 100/1906 (  5%)]  Loss: 2.882 (2.81)  Time: 1.532s,  438.69/s  (1.643s,  409.00/s)  LR: 1.685e-06  Data: 0.014 (0.031)
Train: 0 [ 150/1906 (  8%)]  Loss: 2.532 (2.74)  Time: 1.508s,  445.69/s  (1.600s,  420.07/s)  LR: 1.685e-06  Data: 0.013 (0.025)
Train: 0 [ 200/1906 ( 10%)]  Loss: 2.724 (2.73)  Time: 1.536s,  437.55/s  (1.580s,  425.43/s)  LR: 1.685e-06  Data: 0.014 (0.022)
Train: 0 [ 250/1906 ( 13%)]  Loss: 3.016 (2.78)  Time: 1.518s,  442.59/s  (1.568s,  428.65/s)  LR: 1.685e-06  Data: 0.013 (0.021)
Train: 0 [ 300/1906 ( 16%)]  Loss: 3.183 (2.84)  Time: 1.536s,  437.40/s  (1.559s,  430.93/s)  LR: 1.685e-06  Data: 0.014 (0.019)
Train: 0 [ 350/1906 ( 18%)]  Loss: 2.906 (2.85)  Time: 1.541s,  436.22/s  (1.557s,  431.72/s)  LR: 1.685e-06  Data: 0.013 (0.019)
Train: 0 [ 400/1906 ( 21%)]  Loss: 3.617 (2.93)  Time: 1.538s,  436.95/s  (1.554s,  432.32/s)  LR: 1.685e-06  Data: 0.014 (0.018)
Train: 0 [ 450/1906 ( 24%)]  Loss: 2.637 (2.90)  Time: 1.529s,  439.44/s  (1.551s,  433.36/s)  LR: 1.685e-06  Data: 0.013 (0.018)
Train: 0 [ 500/1906 ( 26%)]  Loss: 2.986 (2.91)  Time: 1.514s,  443.95/s  (1.547s,  434.30/s)  LR: 1.685e-06  Data: 0.014 (0.017)
Train: 0 [ 550/1906 ( 29%)]  Loss: 3.035 (2.92)  Time: 1.511s,  444.78/s  (1.545s,  435.03/s)  LR: 1.685e-06  Data: 0.013 (0.017)
Train: 0 [ 600/1906 ( 31%)]  Loss: 2.391 (2.88)  Time: 1.517s,  442.97/s  (1.542s,  435.67/s)  LR: 1.685e-06  Data: 0.015 (0.017)
Train: 0 [ 650/1906 ( 34%)]  Loss: 3.499 (2.92)  Time: 1.536s,  437.38/s  (1.541s,  436.22/s)  LR: 1.685e-06  Data: 0.013 (0.016)
Train: 0 [ 700/1906 ( 37%)]  Loss: 3.475 (2.96)  Time: 1.508s,  445.75/s  (1.539s,  436.62/s)  LR: 1.685e-06  Data: 0.013 (0.016)
Train: 0 [ 750/1906 ( 39%)]  Loss: 3.085 (2.97)  Time: 1.510s,  444.94/s  (1.538s,  437.04/s)  LR: 1.685e-06  Data: 0.013 (0.016)
Train: 0 [ 800/1906 ( 42%)]  Loss: 3.117 (2.98)  Time: 1.530s,  439.34/s  (1.536s,  437.36/s)  LR: 1.685e-06  Data: 0.014 (0.016)
Train: 0 [ 850/1906 ( 45%)]  Loss: 3.173 (2.99)  Time: 1.525s,  440.55/s  (1.535s,  437.69/s)  LR: 1.685e-06  Data: 0.013 (0.016)
Train: 0 [ 900/1906 ( 47%)]  Loss: 2.684 (2.97)  Time: 1.507s,  446.06/s  (1.535s,  437.88/s)  LR: 1.685e-06  Data: 0.013 (0.016)
Train: 0 [ 950/1906 ( 50%)]  Loss: 2.891 (2.97)  Time: 1.510s,  445.02/s  (1.533s,  438.23/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1000/1906 ( 52%)]  Loss: 2.595 (2.95)  Time: 1.507s,  445.87/s  (1.532s,  438.52/s)  LR: 1.685e-06  Data: 0.014 (0.015)
Train: 0 [1050/1906 ( 55%)]  Loss: 2.997 (2.95)  Time: 1.513s,  444.28/s  (1.532s,  438.73/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1100/1906 ( 58%)]  Loss: 2.799 (2.95)  Time: 1.512s,  444.42/s  (1.531s,  438.98/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1150/1906 ( 60%)]  Loss: 2.960 (2.95)  Time: 1.512s,  444.52/s  (1.530s,  439.22/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1200/1906 ( 63%)]  Loss: 3.104 (2.95)  Time: 1.508s,  445.52/s  (1.529s,  439.45/s)  LR: 1.685e-06  Data: 0.014 (0.015)
Train: 0 [1250/1906 ( 66%)]  Loss: 3.364 (2.97)  Time: 1.528s,  439.92/s  (1.529s,  439.64/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1300/1906 ( 68%)]  Loss: 3.136 (2.97)  Time: 1.540s,  436.44/s  (1.528s,  439.66/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1350/1906 ( 71%)]  Loss: 2.948 (2.97)  Time: 1.514s,  443.80/s  (1.528s,  439.81/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1400/1906 ( 73%)]  Loss: 2.996 (2.97)  Time: 1.532s,  438.60/s  (1.528s,  439.76/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1450/1906 ( 76%)]  Loss: 3.375 (2.99)  Time: 1.511s,  444.83/s  (1.528s,  439.92/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1500/1906 ( 79%)]  Loss: 2.832 (2.98)  Time: 1.509s,  445.33/s  (1.527s,  440.00/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1550/1906 ( 81%)]  Loss: 3.044 (2.98)  Time: 1.510s,  445.01/s  (1.527s,  440.09/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1600/1906 ( 84%)]  Loss: 2.882 (2.98)  Time: 1.509s,  445.21/s  (1.527s,  440.14/s)  LR: 1.685e-06  Data: 0.014 (0.015)
Train: 0 [1650/1906 ( 87%)]  Loss: 3.120 (2.99)  Time: 1.512s,  444.53/s  (1.526s,  440.27/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1700/1906 ( 89%)]  Loss: 2.887 (2.98)  Time: 1.515s,  443.44/s  (1.526s,  440.37/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1750/1906 ( 92%)]  Loss: 2.436 (2.97)  Time: 1.509s,  445.40/s  (1.526s,  440.44/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1800/1906 ( 94%)]  Loss: 2.668 (2.96)  Time: 1.510s,  444.92/s  (1.525s,  440.56/s)  LR: 1.685e-06  Data: 0.014 (0.015)
Train: 0 [1850/1906 ( 97%)]  Loss: 3.018 (2.96)  Time: 1.536s,  437.55/s  (1.525s,  440.59/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1900/1906 (100%)]  Loss: 3.066 (2.96)  Time: 1.536s,  437.53/s  (1.525s,  440.59/s)  LR: 1.685e-06  Data: 0.013 (0.015)
Train: 0 [1905/1906 (100%)]  Loss: 3.231 (2.97)  Time: 1.522s,  441.45/s  (1.525s,  440.59/s)  LR: 1.685e-06  Data: 0.000 (0.015)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 8.736 (8.736)  Loss:  0.4797 (0.4797)  Acc@1: 91.6016 (91.6016)  Acc@5: 97.8516 (97.8516)
Test: [  48/48]  Time: 5.124 (1.060)  Loss:  0.5737 (0.9220)  Acc@1: 86.7925 (79.4000)  Acc@5: 97.6415 (94.9340)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)

Train: 1 [   0/1906 (  0%)]  Loss: 3.016 (3.02)  Time: 2.932s,  229.21/s  (2.932s,  229.21/s)  LR: 1.684e-06  Data: 1.350 (1.350)
Train: 1 [  50/1906 (  3%)]  Loss: 3.218 (3.12)  Time: 1.509s,  445.45/s  (1.543s,  435.52/s)  LR: 1.684e-06  Data: 0.013 (0.040)
Train: 1 [ 100/1906 (  5%)]  Loss: 2.677 (2.97)  Time: 1.507s,  445.86/s  (1.527s,  440.09/s)  LR: 1.684e-06  Data: 0.013 (0.027)
Train: 1 [ 150/1906 (  8%)]  Loss: 3.279 (3.05)  Time: 1.509s,  445.37/s  (1.524s,  441.00/s)  LR: 1.684e-06  Data: 0.013 (0.022)
Train: 1 [ 200/1906 ( 10%)]  Loss: 3.225 (3.08)  Time: 1.508s,  445.77/s  (1.521s,  441.74/s)  LR: 1.684e-06  Data: 0.013 (0.020)
Train: 1 [ 250/1906 ( 13%)]  Loss: 2.986 (3.07)  Time: 1.535s,  437.82/s  (1.522s,  441.62/s)  LR: 1.684e-06  Data: 0.012 (0.019)
Train: 1 [ 300/1906 ( 16%)]  Loss: 3.625 (3.15)  Time: 1.527s,  440.16/s  (1.522s,  441.53/s)  LR: 1.684e-06  Data: 0.013 (0.018)
Train: 1 [ 350/1906 ( 18%)]  Loss: 2.993 (3.13)  Time: 1.510s,  445.12/s  (1.522s,  441.40/s)  LR: 1.684e-06  Data: 0.014 (0.017)
Train: 1 [ 400/1906 ( 21%)]  Loss: 3.110 (3.13)  Time: 1.539s,  436.77/s  (1.523s,  441.10/s)  LR: 1.684e-06  Data: 0.013 (0.016)
Train: 1 [ 450/1906 ( 24%)]  Loss: 3.291 (3.14)  Time: 1.509s,  445.42/s  (1.523s,  441.16/s)  LR: 1.684e-06  Data: 0.012 (0.016)
Train: 1 [ 500/1906 ( 26%)]  Loss: 2.741 (3.11)  Time: 1.511s,  444.79/s  (1.522s,  441.52/s)  LR: 1.684e-06  Data: 0.013 (0.016)
Train: 1 [ 550/1906 ( 29%)]  Loss: 3.371 (3.13)  Time: 1.506s,  446.19/s  (1.521s,  441.70/s)  LR: 1.684e-06  Data: 0.014 (0.016)
Train: 1 [ 600/1906 ( 31%)]  Loss: 2.990 (3.12)  Time: 1.510s,  445.06/s  (1.522s,  441.55/s)  LR: 1.684e-06  Data: 0.013 (0.015)
Train: 1 [ 650/1906 ( 34%)]  Loss: 3.240 (3.13)  Time: 1.509s,  445.29/s  (1.522s,  441.46/s)  LR: 1.684e-06  Data: 0.013 (0.015)
Train: 1 [ 700/1906 ( 37%)]  Loss: 3.603 (3.16)  Time: 1.512s,  444.42/s  (1.521s,  441.70/s)  LR: 1.684e-06  Data: 0.013 (0.015)
Train: 1 [ 750/1906 ( 39%)]  Loss: 2.994 (3.15)  Time: 1.536s,  437.60/s  (1.521s,  441.79/s)  LR: 1.684e-06  Data: 0.013 (0.015)
Train: 1 [ 800/1906 ( 42%)]  Loss: 2.888 (3.13)  Time: 1.535s,  437.79/s  (1.521s,  441.68/s)  LR: 1.684e-06  Data: 0.013 (0.015)
Train: 1 [ 850/1906 ( 45%)]  Loss: 3.100 (3.13)  Time: 1.530s,  439.10/s  (1.522s,  441.64/s)  LR: 1.684e-06  Data: 0.013 (0.015)
Train: 1 [ 900/1906 ( 47%)]  Loss: 3.432 (3.15)  Time: 1.532s,  438.73/s  (1.522s,  441.59/s)  LR: 1.684e-06  Data: 0.012 (0.015)
Train: 1 [ 950/1906 ( 50%)]  Loss: 3.295 (3.15)  Time: 1.532s,  438.69/s  (1.522s,  441.52/s)  LR: 1.684e-06  Data: 0.021 (0.014)
Train: 1 [1000/1906 ( 52%)]  Loss: 2.733 (3.13)  Time: 1.511s,  444.84/s  (1.522s,  441.63/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1050/1906 ( 55%)]  Loss: 3.348 (3.14)  Time: 1.520s,  442.20/s  (1.522s,  441.63/s)  LR: 1.684e-06  Data: 0.012 (0.014)
Train: 1 [1100/1906 ( 58%)]  Loss: 3.121 (3.14)  Time: 1.511s,  444.76/s  (1.522s,  441.60/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1150/1906 ( 60%)]  Loss: 3.162 (3.14)  Time: 1.537s,  437.18/s  (1.522s,  441.64/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1200/1906 ( 63%)]  Loss: 2.808 (3.13)  Time: 1.509s,  445.20/s  (1.522s,  441.64/s)  LR: 1.684e-06  Data: 0.012 (0.014)
Train: 1 [1250/1906 ( 66%)]  Loss: 3.039 (3.13)  Time: 1.507s,  445.78/s  (1.521s,  441.71/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1300/1906 ( 68%)]  Loss: 3.240 (3.13)  Time: 1.508s,  445.77/s  (1.521s,  441.84/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1350/1906 ( 71%)]  Loss: 3.311 (3.14)  Time: 1.515s,  443.51/s  (1.521s,  441.74/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1400/1906 ( 73%)]  Loss: 2.904 (3.13)  Time: 1.513s,  444.27/s  (1.521s,  441.82/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1450/1906 ( 76%)]  Loss: 2.970 (3.12)  Time: 1.507s,  445.86/s  (1.521s,  441.84/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1500/1906 ( 79%)]  Loss: 3.298 (3.13)  Time: 1.509s,  445.34/s  (1.521s,  441.93/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1550/1906 ( 81%)]  Loss: 3.033 (3.13)  Time: 1.547s,  434.45/s  (1.521s,  441.94/s)  LR: 1.684e-06  Data: 0.014 (0.014)
Train: 1 [1600/1906 ( 84%)]  Loss: 2.941 (3.12)  Time: 1.509s,  445.19/s  (1.520s,  442.04/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1650/1906 ( 87%)]  Loss: 2.667 (3.11)  Time: 1.516s,  443.21/s  (1.520s,  442.13/s)  LR: 1.684e-06  Data: 0.020 (0.014)
Train: 1 [1700/1906 ( 89%)]  Loss: 2.688 (3.10)  Time: 1.539s,  436.73/s  (1.520s,  442.10/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1750/1906 ( 92%)]  Loss: 3.049 (3.09)  Time: 1.531s,  438.90/s  (1.520s,  441.97/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1800/1906 ( 94%)]  Loss: 2.688 (3.08)  Time: 1.538s,  436.83/s  (1.521s,  441.84/s)  LR: 1.684e-06  Data: 0.013 (0.014)
Train: 1 [1850/1906 ( 97%)]  Loss: 2.756 (3.07)  Time: 1.537s,  437.31/s  (1.521s,  441.72/s)  LR: 1.684e-06  Data: 0.014 (0.014)
Train: 1 [1900/1906 (100%)]  Loss: 2.873 (3.07)  Time: 1.533s,  438.24/s  (1.522s,  441.60/s)  LR: 1.684e-06  Data: 0.012 (0.014)
Train: 1 [1905/1906 (100%)]  Loss: 3.240 (3.07)  Time: 1.522s,  441.56/s  (1.522s,  441.59/s)  LR: 1.684e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.530 (3.530)  Loss:  0.5137 (0.5137)  Acc@1: 91.5039 (91.5039)  Acc@5: 97.8516 (97.8516)
Test: [  48/48]  Time: 0.771 (0.864)  Loss:  0.6113 (0.9620)  Acc@1: 86.9104 (79.3200)  Acc@5: 97.8773 (94.9020)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)

Train: 2 [   0/1906 (  0%)]  Loss: 3.172 (3.17)  Time: 3.214s,  209.07/s  (3.214s,  209.07/s)  LR: 1.680e-06  Data: 1.679 (1.679)
Train: 2 [  50/1906 (  3%)]  Loss: 2.974 (3.07)  Time: 1.505s,  446.38/s  (1.550s,  433.46/s)  LR: 1.680e-06  Data: 0.013 (0.046)
Train: 2 [ 100/1906 (  5%)]  Loss: 2.821 (2.99)  Time: 1.508s,  445.69/s  (1.531s,  438.86/s)  LR: 1.680e-06  Data: 0.014 (0.030)
Train: 2 [ 150/1906 (  8%)]  Loss: 2.854 (2.96)  Time: 1.508s,  445.51/s  (1.524s,  440.98/s)  LR: 1.680e-06  Data: 0.013 (0.024)
Train: 2 [ 200/1906 ( 10%)]  Loss: 2.713 (2.91)  Time: 1.536s,  437.42/s  (1.525s,  440.64/s)  LR: 1.680e-06  Data: 0.013 (0.021)
Train: 2 [ 250/1906 ( 13%)]  Loss: 3.034 (2.93)  Time: 1.536s,  437.54/s  (1.527s,  440.20/s)  LR: 1.680e-06  Data: 0.013 (0.020)
Train: 2 [ 300/1906 ( 16%)]  Loss: 2.805 (2.91)  Time: 1.507s,  445.97/s  (1.525s,  440.70/s)  LR: 1.680e-06  Data: 0.013 (0.019)
Train: 2 [ 350/1906 ( 18%)]  Loss: 2.901 (2.91)  Time: 1.515s,  443.53/s  (1.524s,  441.05/s)  LR: 1.680e-06  Data: 0.013 (0.018)
Train: 2 [ 400/1906 ( 21%)]  Loss: 3.343 (2.96)  Time: 1.533s,  438.34/s  (1.524s,  440.97/s)  LR: 1.680e-06  Data: 0.013 (0.017)
Train: 2 [ 450/1906 ( 24%)]  Loss: 2.966 (2.96)  Time: 1.510s,  445.05/s  (1.523s,  441.28/s)  LR: 1.680e-06  Data: 0.013 (0.017)
Train: 2 [ 500/1906 ( 26%)]  Loss: 3.012 (2.96)  Time: 1.510s,  445.07/s  (1.521s,  441.67/s)  LR: 1.680e-06  Data: 0.015 (0.017)
Train: 2 [ 550/1906 ( 29%)]  Loss: 3.251 (2.99)  Time: 1.507s,  445.78/s  (1.521s,  441.78/s)  LR: 1.680e-06  Data: 0.013 (0.016)
Train: 2 [ 600/1906 ( 31%)]  Loss: 2.985 (2.99)  Time: 1.513s,  444.12/s  (1.521s,  441.94/s)  LR: 1.680e-06  Data: 0.013 (0.016)
Train: 2 [ 650/1906 ( 34%)]  Loss: 3.053 (2.99)  Time: 1.530s,  439.24/s  (1.521s,  441.86/s)  LR: 1.680e-06  Data: 0.013 (0.016)
Train: 2 [ 700/1906 ( 37%)]  Loss: 2.646 (2.97)  Time: 1.535s,  437.73/s  (1.521s,  441.82/s)  LR: 1.680e-06  Data: 0.013 (0.016)
Train: 2 [ 750/1906 ( 39%)]  Loss: 3.439 (3.00)  Time: 1.534s,  437.93/s  (1.521s,  441.81/s)  LR: 1.680e-06  Data: 0.013 (0.015)
Train: 2 [ 800/1906 ( 42%)]  Loss: 2.896 (2.99)  Time: 1.535s,  437.91/s  (1.522s,  441.62/s)  LR: 1.680e-06  Data: 0.013 (0.015)
Train: 2 [ 850/1906 ( 45%)]  Loss: 2.923 (2.99)  Time: 1.508s,  445.59/s  (1.521s,  441.77/s)  LR: 1.680e-06  Data: 0.013 (0.015)
Train: 2 [ 900/1906 ( 47%)]  Loss: 3.396 (3.01)  Time: 1.510s,  444.95/s  (1.520s,  441.99/s)  LR: 1.680e-06  Data: 0.013 (0.015)
Train: 2 [ 950/1906 ( 50%)]  Loss: 3.022 (3.01)  Time: 1.507s,  445.95/s  (1.520s,  441.96/s)  LR: 1.680e-06  Data: 0.013 (0.015)
Train: 2 [1000/1906 ( 52%)]  Loss: 3.052 (3.01)  Time: 1.507s,  445.80/s  (1.520s,  442.03/s)  LR: 1.680e-06  Data: 0.013 (0.015)
Train: 2 [1050/1906 ( 55%)]  Loss: 3.238 (3.02)  Time: 1.509s,  445.29/s  (1.520s,  442.18/s)  LR: 1.680e-06  Data: 0.013 (0.015)
Train: 2 [1100/1906 ( 58%)]  Loss: 3.358 (3.04)  Time: 1.513s,  444.18/s  (1.520s,  442.24/s)  LR: 1.680e-06  Data: 0.014 (0.015)
Train: 2 [1150/1906 ( 60%)]  Loss: 2.956 (3.03)  Time: 1.528s,  439.65/s  (1.519s,  442.37/s)  LR: 1.680e-06  Data: 0.013 (0.015)
Train: 2 [1200/1906 ( 63%)]  Loss: 2.982 (3.03)  Time: 1.514s,  443.92/s  (1.519s,  442.36/s)  LR: 1.680e-06  Data: 0.014 (0.015)
Train: 2 [1250/1906 ( 66%)]  Loss: 2.879 (3.03)  Time: 1.511s,  444.72/s  (1.519s,  442.48/s)  LR: 1.680e-06  Data: 0.013 (0.015)
Train: 2 [1300/1906 ( 68%)]  Loss: 2.970 (3.02)  Time: 1.517s,  443.06/s  (1.519s,  442.52/s)  LR: 1.680e-06  Data: 0.014 (0.014)
Train: 2 [1350/1906 ( 71%)]  Loss: 3.058 (3.03)  Time: 1.509s,  445.27/s  (1.518s,  442.60/s)  LR: 1.680e-06  Data: 0.013 (0.014)
Train: 2 [1400/1906 ( 73%)]  Loss: 2.973 (3.02)  Time: 1.513s,  444.12/s  (1.518s,  442.69/s)  LR: 1.680e-06  Data: 0.014 (0.014)
Train: 2 [1450/1906 ( 76%)]  Loss: 3.194 (3.03)  Time: 1.534s,  438.17/s  (1.518s,  442.64/s)  LR: 1.680e-06  Data: 0.013 (0.014)
Train: 2 [1500/1906 ( 79%)]  Loss: 2.976 (3.03)  Time: 1.538s,  437.04/s  (1.519s,  442.45/s)  LR: 1.680e-06  Data: 0.013 (0.014)
Train: 2 [1550/1906 ( 81%)]  Loss: 2.896 (3.02)  Time: 1.512s,  444.40/s  (1.519s,  442.45/s)  LR: 1.680e-06  Data: 0.013 (0.014)
Train: 2 [1600/1906 ( 84%)]  Loss: 3.210 (3.03)  Time: 1.537s,  437.23/s  (1.519s,  442.35/s)  LR: 1.680e-06  Data: 0.013 (0.014)
Train: 2 [1650/1906 ( 87%)]  Loss: 3.192 (3.03)  Time: 1.511s,  444.73/s  (1.519s,  442.42/s)  LR: 1.680e-06  Data: 0.014 (0.014)
Train: 2 [1700/1906 ( 89%)]  Loss: 2.651 (3.02)  Time: 1.511s,  444.65/s  (1.519s,  442.50/s)  LR: 1.680e-06  Data: 0.014 (0.014)
Train: 2 [1750/1906 ( 92%)]  Loss: 3.433 (3.03)  Time: 1.504s,  446.67/s  (1.518s,  442.56/s)  LR: 1.680e-06  Data: 0.013 (0.014)
Train: 2 [1800/1906 ( 94%)]  Loss: 3.400 (3.04)  Time: 1.538s,  436.96/s  (1.519s,  442.47/s)  LR: 1.680e-06  Data: 0.013 (0.014)
Train: 2 [1850/1906 ( 97%)]  Loss: 2.923 (3.04)  Time: 1.535s,  437.79/s  (1.519s,  442.33/s)  LR: 1.680e-06  Data: 0.013 (0.014)
Train: 2 [1900/1906 (100%)]  Loss: 3.201 (3.04)  Time: 1.537s,  437.23/s  (1.520s,  442.19/s)  LR: 1.680e-06  Data: 0.012 (0.014)
Train: 2 [1905/1906 (100%)]  Loss: 3.247 (3.05)  Time: 1.523s,  441.24/s  (1.520s,  442.18/s)  LR: 1.680e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.570 (3.570)  Loss:  0.5713 (0.5713)  Acc@1: 91.6992 (91.6992)  Acc@5: 97.9492 (97.9492)
Test: [  48/48]  Time: 0.771 (0.865)  Loss:  0.6611 (1.0107)  Acc@1: 87.1462 (79.2900)  Acc@5: 97.5236 (94.9340)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-2.pth.tar', 79.29000010498046)

Train: 3 [   0/1906 (  0%)]  Loss: 3.167 (3.17)  Time: 2.963s,  226.78/s  (2.963s,  226.78/s)  LR: 1.675e-06  Data: 1.309 (1.309)
Train: 3 [  50/1906 (  3%)]  Loss: 3.100 (3.13)  Time: 1.505s,  446.55/s  (1.542s,  435.87/s)  LR: 1.675e-06  Data: 0.014 (0.038)
Train: 3 [ 100/1906 (  5%)]  Loss: 2.573 (2.95)  Time: 1.526s,  440.46/s  (1.528s,  439.90/s)  LR: 1.675e-06  Data: 0.013 (0.026)
Train: 3 [ 150/1906 (  8%)]  Loss: 2.546 (2.85)  Time: 1.510s,  445.03/s  (1.522s,  441.58/s)  LR: 1.675e-06  Data: 0.014 (0.022)
Train: 3 [ 200/1906 ( 10%)]  Loss: 2.847 (2.85)  Time: 1.512s,  444.57/s  (1.522s,  441.63/s)  LR: 1.675e-06  Data: 0.012 (0.020)
Train: 3 [ 250/1906 ( 13%)]  Loss: 3.313 (2.92)  Time: 1.506s,  446.15/s  (1.522s,  441.66/s)  LR: 1.675e-06  Data: 0.014 (0.018)
Train: 3 [ 300/1906 ( 16%)]  Loss: 2.817 (2.91)  Time: 1.513s,  444.23/s  (1.520s,  442.17/s)  LR: 1.675e-06  Data: 0.013 (0.018)
Train: 3 [ 350/1906 ( 18%)]  Loss: 2.966 (2.92)  Time: 1.513s,  444.19/s  (1.520s,  442.25/s)  LR: 1.675e-06  Data: 0.014 (0.017)
Train: 3 [ 400/1906 ( 21%)]  Loss: 3.395 (2.97)  Time: 1.514s,  443.99/s  (1.519s,  442.47/s)  LR: 1.675e-06  Data: 0.013 (0.016)
Train: 3 [ 450/1906 ( 24%)]  Loss: 3.285 (3.00)  Time: 1.509s,  445.32/s  (1.519s,  442.49/s)  LR: 1.675e-06  Data: 0.014 (0.016)
Train: 3 [ 500/1906 ( 26%)]  Loss: 2.724 (2.98)  Time: 1.539s,  436.75/s  (1.519s,  442.34/s)  LR: 1.675e-06  Data: 0.013 (0.016)
Train: 3 [ 550/1906 ( 29%)]  Loss: 3.388 (3.01)  Time: 1.530s,  439.09/s  (1.521s,  441.96/s)  LR: 1.675e-06  Data: 0.013 (0.016)
Train: 3 [ 600/1906 ( 31%)]  Loss: 2.768 (2.99)  Time: 1.507s,  445.87/s  (1.521s,  441.79/s)  LR: 1.675e-06  Data: 0.013 (0.015)
Train: 3 [ 650/1906 ( 34%)]  Loss: 2.854 (2.98)  Time: 1.534s,  438.04/s  (1.521s,  441.95/s)  LR: 1.675e-06  Data: 0.013 (0.015)
Train: 3 [ 700/1906 ( 37%)]  Loss: 2.858 (2.97)  Time: 1.540s,  436.40/s  (1.521s,  441.76/s)  LR: 1.675e-06  Data: 0.013 (0.015)
Train: 3 [ 750/1906 ( 39%)]  Loss: 2.753 (2.96)  Time: 1.525s,  440.70/s  (1.521s,  441.80/s)  LR: 1.675e-06  Data: 0.013 (0.015)
Train: 3 [ 800/1906 ( 42%)]  Loss: 2.768 (2.95)  Time: 1.508s,  445.69/s  (1.521s,  441.87/s)  LR: 1.675e-06  Data: 0.013 (0.015)
Train: 3 [ 850/1906 ( 45%)]  Loss: 2.946 (2.95)  Time: 1.504s,  446.68/s  (1.520s,  442.08/s)  LR: 1.675e-06  Data: 0.013 (0.015)
Train: 3 [ 900/1906 ( 47%)]  Loss: 3.005 (2.95)  Time: 1.506s,  446.27/s  (1.520s,  442.25/s)  LR: 1.675e-06  Data: 0.013 (0.015)
Train: 3 [ 950/1906 ( 50%)]  Loss: 2.652 (2.94)  Time: 1.507s,  445.86/s  (1.519s,  442.42/s)  LR: 1.675e-06  Data: 0.014 (0.015)
Train: 3 [1000/1906 ( 52%)]  Loss: 3.030 (2.94)  Time: 1.505s,  446.49/s  (1.518s,  442.56/s)  LR: 1.675e-06  Data: 0.013 (0.015)
Train: 3 [1050/1906 ( 55%)]  Loss: 3.028 (2.94)  Time: 1.535s,  437.81/s  (1.519s,  442.51/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1100/1906 ( 58%)]  Loss: 2.997 (2.95)  Time: 1.508s,  445.65/s  (1.519s,  442.34/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1150/1906 ( 60%)]  Loss: 3.091 (2.95)  Time: 1.512s,  444.46/s  (1.519s,  442.47/s)  LR: 1.675e-06  Data: 0.014 (0.014)
Train: 3 [1200/1906 ( 63%)]  Loss: 3.106 (2.96)  Time: 1.534s,  437.98/s  (1.519s,  442.43/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1250/1906 ( 66%)]  Loss: 3.045 (2.96)  Time: 1.535s,  437.75/s  (1.520s,  442.25/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1300/1906 ( 68%)]  Loss: 3.139 (2.97)  Time: 1.533s,  438.28/s  (1.520s,  442.08/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1350/1906 ( 71%)]  Loss: 2.798 (2.96)  Time: 1.536s,  437.46/s  (1.521s,  441.93/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1400/1906 ( 73%)]  Loss: 2.967 (2.96)  Time: 1.507s,  445.77/s  (1.520s,  441.99/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1450/1906 ( 76%)]  Loss: 3.080 (2.97)  Time: 1.507s,  445.88/s  (1.520s,  442.09/s)  LR: 1.675e-06  Data: 0.014 (0.014)
Train: 3 [1500/1906 ( 79%)]  Loss: 3.314 (2.98)  Time: 1.507s,  446.06/s  (1.520s,  442.05/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1550/1906 ( 81%)]  Loss: 3.313 (2.99)  Time: 1.536s,  437.63/s  (1.521s,  441.90/s)  LR: 1.675e-06  Data: 0.014 (0.014)
Train: 3 [1600/1906 ( 84%)]  Loss: 2.819 (2.98)  Time: 1.512s,  444.32/s  (1.521s,  441.95/s)  LR: 1.675e-06  Data: 0.014 (0.014)
Train: 3 [1650/1906 ( 87%)]  Loss: 2.991 (2.98)  Time: 1.510s,  445.10/s  (1.520s,  442.05/s)  LR: 1.675e-06  Data: 0.015 (0.014)
Train: 3 [1700/1906 ( 89%)]  Loss: 3.249 (2.99)  Time: 1.507s,  446.04/s  (1.520s,  442.14/s)  LR: 1.675e-06  Data: 0.014 (0.014)
Train: 3 [1750/1906 ( 92%)]  Loss: 3.101 (2.99)  Time: 1.508s,  445.62/s  (1.520s,  442.22/s)  LR: 1.675e-06  Data: 0.014 (0.014)
Train: 3 [1800/1906 ( 94%)]  Loss: 3.136 (3.00)  Time: 1.524s,  440.80/s  (1.520s,  442.18/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1850/1906 ( 97%)]  Loss: 2.915 (3.00)  Time: 1.526s,  440.33/s  (1.520s,  442.12/s)  LR: 1.675e-06  Data: 0.014 (0.014)
Train: 3 [1900/1906 (100%)]  Loss: 3.030 (3.00)  Time: 1.511s,  444.72/s  (1.520s,  442.15/s)  LR: 1.675e-06  Data: 0.013 (0.014)
Train: 3 [1905/1906 (100%)]  Loss: 2.877 (2.99)  Time: 1.491s,  450.68/s  (1.520s,  442.16/s)  LR: 1.675e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.536 (3.536)  Loss:  0.5137 (0.5137)  Acc@1: 91.6992 (91.6992)  Acc@5: 97.9492 (97.9492)
Test: [  48/48]  Time: 0.771 (0.864)  Loss:  0.6055 (0.9582)  Acc@1: 87.1462 (79.3860)  Acc@5: 97.7594 (94.9640)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-2.pth.tar', 79.29000010498046)

Train: 4 [   0/1906 (  0%)]  Loss: 2.738 (2.74)  Time: 2.962s,  226.88/s  (2.962s,  226.88/s)  LR: 1.666e-06  Data: 1.400 (1.400)
Train: 4 [  50/1906 (  3%)]  Loss: 2.944 (2.84)  Time: 1.509s,  445.39/s  (1.539s,  436.76/s)  LR: 1.666e-06  Data: 0.014 (0.041)
Train: 4 [ 100/1906 (  5%)]  Loss: 2.878 (2.85)  Time: 1.511s,  444.72/s  (1.525s,  440.72/s)  LR: 1.666e-06  Data: 0.015 (0.027)
Train: 4 [ 150/1906 (  8%)]  Loss: 2.377 (2.73)  Time: 1.513s,  444.11/s  (1.520s,  442.01/s)  LR: 1.666e-06  Data: 0.013 (0.023)
Train: 4 [ 200/1906 ( 10%)]  Loss: 3.287 (2.84)  Time: 1.535s,  437.82/s  (1.522s,  441.51/s)  LR: 1.666e-06  Data: 0.013 (0.020)
Train: 4 [ 250/1906 ( 13%)]  Loss: 2.775 (2.83)  Time: 1.514s,  443.95/s  (1.520s,  442.13/s)  LR: 1.666e-06  Data: 0.013 (0.019)
Train: 4 [ 300/1906 ( 16%)]  Loss: 3.277 (2.90)  Time: 1.510s,  445.02/s  (1.518s,  442.58/s)  LR: 1.666e-06  Data: 0.014 (0.018)
Train: 4 [ 350/1906 ( 18%)]  Loss: 2.936 (2.90)  Time: 1.512s,  444.36/s  (1.517s,  442.88/s)  LR: 1.666e-06  Data: 0.013 (0.017)
Train: 4 [ 400/1906 ( 21%)]  Loss: 2.723 (2.88)  Time: 1.514s,  443.73/s  (1.517s,  442.91/s)  LR: 1.666e-06  Data: 0.013 (0.017)
Train: 4 [ 450/1906 ( 24%)]  Loss: 3.229 (2.92)  Time: 1.507s,  446.04/s  (1.517s,  443.12/s)  LR: 1.666e-06  Data: 0.013 (0.017)
Train: 4 [ 500/1906 ( 26%)]  Loss: 3.294 (2.95)  Time: 1.536s,  437.48/s  (1.516s,  443.22/s)  LR: 1.666e-06  Data: 0.014 (0.016)
Train: 4 [ 550/1906 ( 29%)]  Loss: 2.708 (2.93)  Time: 1.537s,  437.13/s  (1.518s,  442.71/s)  LR: 1.666e-06  Data: 0.013 (0.016)
Train: 4 [ 600/1906 ( 31%)]  Loss: 2.734 (2.92)  Time: 1.542s,  435.78/s  (1.518s,  442.77/s)  LR: 1.666e-06  Data: 0.020 (0.016)
Train: 4 [ 650/1906 ( 34%)]  Loss: 2.873 (2.91)  Time: 1.513s,  444.23/s  (1.518s,  442.79/s)  LR: 1.666e-06  Data: 0.013 (0.016)
Train: 4 [ 700/1906 ( 37%)]  Loss: 2.839 (2.91)  Time: 1.512s,  444.49/s  (1.518s,  442.69/s)  LR: 1.666e-06  Data: 0.015 (0.015)
Train: 4 [ 750/1906 ( 39%)]  Loss: 2.583 (2.89)  Time: 1.515s,  443.61/s  (1.518s,  442.65/s)  LR: 1.666e-06  Data: 0.013 (0.015)
Train: 4 [ 800/1906 ( 42%)]  Loss: 3.397 (2.92)  Time: 1.508s,  445.57/s  (1.518s,  442.77/s)  LR: 1.666e-06  Data: 0.014 (0.015)
Train: 4 [ 850/1906 ( 45%)]  Loss: 3.047 (2.92)  Time: 1.533s,  438.49/s  (1.518s,  442.76/s)  LR: 1.666e-06  Data: 0.013 (0.015)
Train: 4 [ 900/1906 ( 47%)]  Loss: 3.046 (2.93)  Time: 1.532s,  438.66/s  (1.518s,  442.81/s)  LR: 1.666e-06  Data: 0.014 (0.015)
Train: 4 [ 950/1906 ( 50%)]  Loss: 3.040 (2.94)  Time: 1.517s,  442.97/s  (1.518s,  442.76/s)  LR: 1.666e-06  Data: 0.013 (0.015)
Train: 4 [1000/1906 ( 52%)]  Loss: 2.729 (2.93)  Time: 1.513s,  444.12/s  (1.517s,  442.85/s)  LR: 1.666e-06  Data: 0.014 (0.015)
Train: 4 [1050/1906 ( 55%)]  Loss: 3.059 (2.93)  Time: 1.509s,  445.35/s  (1.517s,  442.94/s)  LR: 1.666e-06  Data: 0.013 (0.015)
Train: 4 [1100/1906 ( 58%)]  Loss: 2.980 (2.93)  Time: 1.511s,  444.86/s  (1.517s,  443.02/s)  LR: 1.666e-06  Data: 0.014 (0.015)
Train: 4 [1150/1906 ( 60%)]  Loss: 2.833 (2.93)  Time: 1.511s,  444.69/s  (1.517s,  443.09/s)  LR: 1.666e-06  Data: 0.013 (0.015)
Train: 4 [1200/1906 ( 63%)]  Loss: 2.892 (2.93)  Time: 1.512s,  444.54/s  (1.517s,  443.05/s)  LR: 1.666e-06  Data: 0.014 (0.015)
Train: 4 [1250/1906 ( 66%)]  Loss: 2.882 (2.93)  Time: 1.515s,  443.60/s  (1.517s,  443.10/s)  LR: 1.666e-06  Data: 0.013 (0.015)
Train: 4 [1300/1906 ( 68%)]  Loss: 3.106 (2.93)  Time: 1.508s,  445.53/s  (1.516s,  443.16/s)  LR: 1.666e-06  Data: 0.014 (0.015)
Train: 4 [1350/1906 ( 71%)]  Loss: 3.020 (2.94)  Time: 1.511s,  444.67/s  (1.516s,  443.13/s)  LR: 1.666e-06  Data: 0.013 (0.015)
Train: 4 [1400/1906 ( 73%)]  Loss: 2.938 (2.94)  Time: 1.518s,  442.71/s  (1.516s,  443.18/s)  LR: 1.666e-06  Data: 0.020 (0.015)
Train: 4 [1450/1906 ( 76%)]  Loss: 3.362 (2.95)  Time: 1.510s,  445.10/s  (1.516s,  443.23/s)  LR: 1.666e-06  Data: 0.013 (0.015)
Train: 4 [1500/1906 ( 79%)]  Loss: 3.162 (2.96)  Time: 1.510s,  444.91/s  (1.516s,  443.27/s)  LR: 1.666e-06  Data: 0.014 (0.015)
Train: 4 [1550/1906 ( 81%)]  Loss: 2.773 (2.95)  Time: 1.512s,  444.44/s  (1.516s,  443.27/s)  LR: 1.666e-06  Data: 0.013 (0.015)
Train: 4 [1600/1906 ( 84%)]  Loss: 3.343 (2.96)  Time: 1.538s,  436.84/s  (1.516s,  443.22/s)  LR: 1.666e-06  Data: 0.014 (0.014)
Train: 4 [1650/1906 ( 87%)]  Loss: 3.023 (2.97)  Time: 1.511s,  444.65/s  (1.516s,  443.26/s)  LR: 1.666e-06  Data: 0.014 (0.014)
Train: 4 [1700/1906 ( 89%)]  Loss: 2.679 (2.96)  Time: 1.512s,  444.32/s  (1.516s,  443.28/s)  LR: 1.666e-06  Data: 0.014 (0.014)
Train: 4 [1750/1906 ( 92%)]  Loss: 3.119 (2.96)  Time: 1.511s,  444.79/s  (1.516s,  443.32/s)  LR: 1.666e-06  Data: 0.013 (0.014)
Train: 4 [1800/1906 ( 94%)]  Loss: 3.134 (2.97)  Time: 1.515s,  443.57/s  (1.516s,  443.34/s)  LR: 1.666e-06  Data: 0.014 (0.014)
Train: 4 [1850/1906 ( 97%)]  Loss: 2.620 (2.96)  Time: 1.512s,  444.49/s  (1.516s,  443.37/s)  LR: 1.666e-06  Data: 0.014 (0.014)
Train: 4 [1900/1906 (100%)]  Loss: 2.806 (2.95)  Time: 1.510s,  445.09/s  (1.516s,  443.40/s)  LR: 1.666e-06  Data: 0.014 (0.014)
Train: 4 [1905/1906 (100%)]  Loss: 2.763 (2.95)  Time: 1.497s,  448.82/s  (1.516s,  443.41/s)  LR: 1.666e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.597 (3.597)  Loss:  0.5000 (0.5000)  Acc@1: 91.7969 (91.7969)  Acc@5: 98.0469 (98.0469)
Test: [  48/48]  Time: 0.774 (0.866)  Loss:  0.5977 (0.9473)  Acc@1: 87.6179 (79.4200)  Acc@5: 97.7594 (94.9880)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-2.pth.tar', 79.29000010498046)

Train: 5 [   0/1906 (  0%)]  Loss: 3.039 (3.04)  Time: 3.078s,  218.36/s  (3.078s,  218.36/s)  LR: 1.656e-06  Data: 1.516 (1.516)
Train: 5 [  50/1906 (  3%)]  Loss: 3.247 (3.14)  Time: 1.513s,  444.05/s  (1.552s,  432.93/s)  LR: 1.656e-06  Data: 0.015 (0.043)
Train: 5 [ 100/1906 (  5%)]  Loss: 2.817 (3.03)  Time: 1.509s,  445.20/s  (1.531s,  438.80/s)  LR: 1.656e-06  Data: 0.014 (0.028)
Train: 5 [ 150/1906 (  8%)]  Loss: 3.267 (3.09)  Time: 1.530s,  439.21/s  (1.530s,  439.25/s)  LR: 1.656e-06  Data: 0.013 (0.024)
Train: 5 [ 200/1906 ( 10%)]  Loss: 2.792 (3.03)  Time: 1.502s,  447.31/s  (1.528s,  439.82/s)  LR: 1.656e-06  Data: 0.013 (0.021)
Train: 5 [ 250/1906 ( 13%)]  Loss: 2.682 (2.97)  Time: 1.512s,  444.52/s  (1.524s,  440.82/s)  LR: 1.656e-06  Data: 0.014 (0.020)
Train: 5 [ 300/1906 ( 16%)]  Loss: 2.978 (2.97)  Time: 1.526s,  440.29/s  (1.522s,  441.41/s)  LR: 1.656e-06  Data: 0.013 (0.019)
Train: 5 [ 350/1906 ( 18%)]  Loss: 3.137 (2.99)  Time: 1.517s,  443.06/s  (1.523s,  441.20/s)  LR: 1.656e-06  Data: 0.021 (0.018)
Train: 5 [ 400/1906 ( 21%)]  Loss: 3.025 (3.00)  Time: 1.509s,  445.19/s  (1.522s,  441.65/s)  LR: 1.656e-06  Data: 0.013 (0.017)
Train: 5 [ 450/1906 ( 24%)]  Loss: 3.003 (3.00)  Time: 1.511s,  444.85/s  (1.520s,  442.00/s)  LR: 1.656e-06  Data: 0.014 (0.017)
Train: 5 [ 500/1906 ( 26%)]  Loss: 3.046 (3.00)  Time: 1.510s,  444.92/s  (1.520s,  442.09/s)  LR: 1.656e-06  Data: 0.013 (0.017)
Train: 5 [ 550/1906 ( 29%)]  Loss: 3.024 (3.00)  Time: 1.535s,  437.92/s  (1.520s,  442.24/s)  LR: 1.656e-06  Data: 0.013 (0.016)
Train: 5 [ 600/1906 ( 31%)]  Loss: 3.051 (3.01)  Time: 1.505s,  446.52/s  (1.519s,  442.46/s)  LR: 1.656e-06  Data: 0.013 (0.016)
Train: 5 [ 650/1906 ( 34%)]  Loss: 3.307 (3.03)  Time: 1.513s,  444.06/s  (1.518s,  442.60/s)  LR: 1.656e-06  Data: 0.015 (0.016)
Train: 5 [ 700/1906 ( 37%)]  Loss: 2.997 (3.03)  Time: 1.508s,  445.48/s  (1.518s,  442.79/s)  LR: 1.656e-06  Data: 0.013 (0.016)
Train: 5 [ 750/1906 ( 39%)]  Loss: 2.956 (3.02)  Time: 1.541s,  436.19/s  (1.518s,  442.75/s)  LR: 1.656e-06  Data: 0.013 (0.016)
Train: 5 [ 800/1906 ( 42%)]  Loss: 2.982 (3.02)  Time: 1.509s,  445.46/s  (1.519s,  442.48/s)  LR: 1.656e-06  Data: 0.013 (0.016)
Train: 5 [ 850/1906 ( 45%)]  Loss: 3.006 (3.02)  Time: 1.539s,  436.53/s  (1.519s,  442.53/s)  LR: 1.656e-06  Data: 0.014 (0.015)
Train: 5 [ 900/1906 ( 47%)]  Loss: 2.938 (3.02)  Time: 1.513s,  444.12/s  (1.518s,  442.58/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [ 950/1906 ( 50%)]  Loss: 3.119 (3.02)  Time: 1.507s,  445.90/s  (1.518s,  442.63/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1000/1906 ( 52%)]  Loss: 2.777 (3.01)  Time: 1.512s,  444.42/s  (1.518s,  442.75/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1050/1906 ( 55%)]  Loss: 3.120 (3.01)  Time: 1.536s,  437.57/s  (1.518s,  442.54/s)  LR: 1.656e-06  Data: 0.014 (0.015)
Train: 5 [1100/1906 ( 58%)]  Loss: 3.065 (3.02)  Time: 1.506s,  446.16/s  (1.519s,  442.51/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1150/1906 ( 60%)]  Loss: 2.524 (3.00)  Time: 1.509s,  445.34/s  (1.518s,  442.58/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1200/1906 ( 63%)]  Loss: 3.187 (3.00)  Time: 1.509s,  445.44/s  (1.518s,  442.69/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1250/1906 ( 66%)]  Loss: 2.611 (2.99)  Time: 1.513s,  444.17/s  (1.518s,  442.77/s)  LR: 1.656e-06  Data: 0.014 (0.015)
Train: 5 [1300/1906 ( 68%)]  Loss: 2.544 (2.97)  Time: 1.508s,  445.57/s  (1.517s,  442.86/s)  LR: 1.656e-06  Data: 0.014 (0.015)
Train: 5 [1350/1906 ( 71%)]  Loss: 2.809 (2.97)  Time: 1.506s,  446.08/s  (1.517s,  442.94/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1400/1906 ( 73%)]  Loss: 2.837 (2.96)  Time: 1.508s,  445.71/s  (1.517s,  443.01/s)  LR: 1.656e-06  Data: 0.014 (0.015)
Train: 5 [1450/1906 ( 76%)]  Loss: 3.576 (2.98)  Time: 1.511s,  444.59/s  (1.517s,  443.03/s)  LR: 1.656e-06  Data: 0.014 (0.015)
Train: 5 [1500/1906 ( 79%)]  Loss: 2.781 (2.98)  Time: 1.508s,  445.76/s  (1.517s,  443.09/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1550/1906 ( 81%)]  Loss: 3.002 (2.98)  Time: 1.508s,  445.57/s  (1.517s,  443.06/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1600/1906 ( 84%)]  Loss: 3.108 (2.98)  Time: 1.504s,  446.82/s  (1.516s,  443.13/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1650/1906 ( 87%)]  Loss: 3.256 (2.99)  Time: 1.507s,  445.81/s  (1.516s,  443.18/s)  LR: 1.656e-06  Data: 0.014 (0.015)
Train: 5 [1700/1906 ( 89%)]  Loss: 2.801 (2.98)  Time: 1.508s,  445.75/s  (1.516s,  443.23/s)  LR: 1.656e-06  Data: 0.013 (0.015)
Train: 5 [1750/1906 ( 92%)]  Loss: 3.211 (2.99)  Time: 1.509s,  445.19/s  (1.516s,  443.28/s)  LR: 1.656e-06  Data: 0.014 (0.015)
Train: 5 [1800/1906 ( 94%)]  Loss: 3.068 (2.99)  Time: 1.517s,  442.85/s  (1.516s,  443.33/s)  LR: 1.656e-06  Data: 0.020 (0.015)
Train: 5 [1850/1906 ( 97%)]  Loss: 3.346 (3.00)  Time: 1.509s,  445.39/s  (1.516s,  443.38/s)  LR: 1.656e-06  Data: 0.014 (0.014)
Train: 5 [1900/1906 (100%)]  Loss: 2.735 (2.99)  Time: 1.533s,  438.41/s  (1.516s,  443.37/s)  LR: 1.656e-06  Data: 0.013 (0.014)
Train: 5 [1905/1906 (100%)]  Loss: 2.981 (2.99)  Time: 1.521s,  441.82/s  (1.516s,  443.36/s)  LR: 1.656e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.573 (3.573)  Loss:  0.5312 (0.5312)  Acc@1: 91.7969 (91.7969)  Acc@5: 98.0469 (98.0469)
Test: [  48/48]  Time: 0.769 (0.866)  Loss:  0.6255 (0.9803)  Acc@1: 87.6179 (79.3120)  Acc@5: 97.5236 (94.9140)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-5.pth.tar', 79.31200005126954)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-2.pth.tar', 79.29000010498046)

Train: 6 [   0/1906 (  0%)]  Loss: 3.155 (3.16)  Time: 3.054s,  220.06/s  (3.054s,  220.06/s)  LR: 1.643e-06  Data: 1.547 (1.547)
Train: 6 [  50/1906 (  3%)]  Loss: 3.340 (3.25)  Time: 1.537s,  437.17/s  (1.548s,  434.02/s)  LR: 1.643e-06  Data: 0.014 (0.044)
Train: 6 [ 100/1906 (  5%)]  Loss: 2.711 (3.07)  Time: 1.510s,  444.98/s  (1.532s,  438.76/s)  LR: 1.643e-06  Data: 0.013 (0.029)
Train: 6 [ 150/1906 (  8%)]  Loss: 3.069 (3.07)  Time: 1.506s,  446.29/s  (1.525s,  440.70/s)  LR: 1.643e-06  Data: 0.013 (0.024)
Train: 6 [ 200/1906 ( 10%)]  Loss: 3.161 (3.09)  Time: 1.511s,  444.77/s  (1.521s,  441.72/s)  LR: 1.643e-06  Data: 0.014 (0.021)
Train: 6 [ 250/1906 ( 13%)]  Loss: 3.248 (3.11)  Time: 1.507s,  446.00/s  (1.523s,  441.25/s)  LR: 1.643e-06  Data: 0.014 (0.020)
Train: 6 [ 300/1906 ( 16%)]  Loss: 3.067 (3.11)  Time: 1.511s,  444.73/s  (1.523s,  441.13/s)  LR: 1.643e-06  Data: 0.013 (0.019)
Train: 6 [ 350/1906 ( 18%)]  Loss: 3.065 (3.10)  Time: 1.509s,  445.21/s  (1.522s,  441.56/s)  LR: 1.643e-06  Data: 0.013 (0.018)
Train: 6 [ 400/1906 ( 21%)]  Loss: 2.891 (3.08)  Time: 1.513s,  444.22/s  (1.521s,  441.96/s)  LR: 1.643e-06  Data: 0.014 (0.017)
Train: 6 [ 450/1906 ( 24%)]  Loss: 2.858 (3.06)  Time: 1.508s,  445.58/s  (1.519s,  442.28/s)  LR: 1.643e-06  Data: 0.013 (0.017)
Train: 6 [ 500/1906 ( 26%)]  Loss: 3.290 (3.08)  Time: 1.512s,  444.41/s  (1.519s,  442.52/s)  LR: 1.643e-06  Data: 0.013 (0.017)
Train: 6 [ 550/1906 ( 29%)]  Loss: 3.196 (3.09)  Time: 1.538s,  436.92/s  (1.519s,  442.52/s)  LR: 1.643e-06  Data: 0.013 (0.016)
Train: 6 [ 600/1906 ( 31%)]  Loss: 3.418 (3.11)  Time: 1.532s,  438.54/s  (1.520s,  442.25/s)  LR: 1.643e-06  Data: 0.014 (0.016)
Train: 6 [ 650/1906 ( 34%)]  Loss: 2.910 (3.10)  Time: 1.510s,  445.13/s  (1.519s,  442.42/s)  LR: 1.643e-06  Data: 0.015 (0.016)
Train: 6 [ 700/1906 ( 37%)]  Loss: 2.723 (3.07)  Time: 1.535s,  437.87/s  (1.519s,  442.26/s)  LR: 1.643e-06  Data: 0.013 (0.016)
Train: 6 [ 750/1906 ( 39%)]  Loss: 2.996 (3.07)  Time: 1.508s,  445.56/s  (1.519s,  442.29/s)  LR: 1.643e-06  Data: 0.014 (0.016)
Train: 6 [ 800/1906 ( 42%)]  Loss: 3.073 (3.07)  Time: 1.508s,  445.52/s  (1.519s,  442.43/s)  LR: 1.643e-06  Data: 0.014 (0.016)
Train: 6 [ 850/1906 ( 45%)]  Loss: 3.008 (3.07)  Time: 1.512s,  444.40/s  (1.518s,  442.56/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [ 900/1906 ( 47%)]  Loss: 2.943 (3.06)  Time: 1.507s,  445.93/s  (1.518s,  442.67/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [ 950/1906 ( 50%)]  Loss: 2.882 (3.05)  Time: 1.532s,  438.52/s  (1.518s,  442.63/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1000/1906 ( 52%)]  Loss: 3.066 (3.05)  Time: 1.534s,  438.18/s  (1.518s,  442.65/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1050/1906 ( 55%)]  Loss: 2.927 (3.05)  Time: 1.531s,  438.81/s  (1.518s,  442.61/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1100/1906 ( 58%)]  Loss: 2.936 (3.04)  Time: 1.513s,  444.05/s  (1.518s,  442.69/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1150/1906 ( 60%)]  Loss: 2.856 (3.03)  Time: 1.536s,  437.45/s  (1.518s,  442.76/s)  LR: 1.643e-06  Data: 0.014 (0.015)
Train: 6 [1200/1906 ( 63%)]  Loss: 3.218 (3.04)  Time: 1.510s,  444.95/s  (1.518s,  442.81/s)  LR: 1.643e-06  Data: 0.014 (0.015)
Train: 6 [1250/1906 ( 66%)]  Loss: 2.879 (3.03)  Time: 1.513s,  444.30/s  (1.518s,  442.78/s)  LR: 1.643e-06  Data: 0.014 (0.015)
Train: 6 [1300/1906 ( 68%)]  Loss: 3.049 (3.03)  Time: 1.534s,  438.02/s  (1.518s,  442.78/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1350/1906 ( 71%)]  Loss: 2.925 (3.03)  Time: 1.510s,  445.03/s  (1.518s,  442.72/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1400/1906 ( 73%)]  Loss: 2.654 (3.02)  Time: 1.511s,  444.71/s  (1.518s,  442.79/s)  LR: 1.643e-06  Data: 0.015 (0.015)
Train: 6 [1450/1906 ( 76%)]  Loss: 2.917 (3.01)  Time: 1.512s,  444.48/s  (1.517s,  442.85/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1500/1906 ( 79%)]  Loss: 3.302 (3.02)  Time: 1.511s,  444.76/s  (1.517s,  442.91/s)  LR: 1.643e-06  Data: 0.014 (0.015)
Train: 6 [1550/1906 ( 81%)]  Loss: 2.883 (3.02)  Time: 1.509s,  445.37/s  (1.517s,  442.97/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1600/1906 ( 84%)]  Loss: 2.536 (3.00)  Time: 1.539s,  436.78/s  (1.517s,  442.92/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1650/1906 ( 87%)]  Loss: 2.890 (3.00)  Time: 1.535s,  437.80/s  (1.518s,  442.74/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1700/1906 ( 89%)]  Loss: 2.524 (2.99)  Time: 1.509s,  445.19/s  (1.518s,  442.67/s)  LR: 1.643e-06  Data: 0.014 (0.015)
Train: 6 [1750/1906 ( 92%)]  Loss: 2.590 (2.98)  Time: 1.533s,  438.43/s  (1.518s,  442.61/s)  LR: 1.643e-06  Data: 0.014 (0.015)
Train: 6 [1800/1906 ( 94%)]  Loss: 3.001 (2.98)  Time: 1.508s,  445.76/s  (1.519s,  442.53/s)  LR: 1.643e-06  Data: 0.014 (0.015)
Train: 6 [1850/1906 ( 97%)]  Loss: 2.993 (2.98)  Time: 1.537s,  437.32/s  (1.518s,  442.57/s)  LR: 1.643e-06  Data: 0.013 (0.015)
Train: 6 [1900/1906 (100%)]  Loss: 2.682 (2.97)  Time: 1.510s,  445.00/s  (1.518s,  442.60/s)  LR: 1.643e-06  Data: 0.014 (0.015)
Train: 6 [1905/1906 (100%)]  Loss: 3.361 (2.98)  Time: 1.494s,  449.72/s  (1.518s,  442.61/s)  LR: 1.643e-06  Data: 0.000 (0.015)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.594 (3.594)  Loss:  0.5439 (0.5439)  Acc@1: 91.9922 (91.9922)  Acc@5: 97.9492 (97.9492)
Test: [  48/48]  Time: 0.774 (0.865)  Loss:  0.6333 (0.9907)  Acc@1: 87.3821 (79.3840)  Acc@5: 97.6415 (94.9040)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-6.pth.tar', 79.384000078125)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-5.pth.tar', 79.31200005126954)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-2.pth.tar', 79.29000010498046)

Train: 7 [   0/1906 (  0%)]  Loss: 3.265 (3.26)  Time: 2.980s,  225.48/s  (2.980s,  225.48/s)  LR: 1.629e-06  Data: 1.450 (1.450)
Train: 7 [  50/1906 (  3%)]  Loss: 2.808 (3.04)  Time: 1.516s,  443.31/s  (1.549s,  433.94/s)  LR: 1.629e-06  Data: 0.014 (0.042)
Train: 7 [ 100/1906 (  5%)]  Loss: 2.724 (2.93)  Time: 1.507s,  445.94/s  (1.529s,  439.39/s)  LR: 1.629e-06  Data: 0.013 (0.028)
Train: 7 [ 150/1906 (  8%)]  Loss: 2.797 (2.90)  Time: 1.513s,  444.08/s  (1.524s,  440.88/s)  LR: 1.629e-06  Data: 0.016 (0.023)
Train: 7 [ 200/1906 ( 10%)]  Loss: 3.073 (2.93)  Time: 1.509s,  445.36/s  (1.524s,  441.07/s)  LR: 1.629e-06  Data: 0.013 (0.021)
Train: 7 [ 250/1906 ( 13%)]  Loss: 2.830 (2.92)  Time: 1.513s,  444.29/s  (1.521s,  441.84/s)  LR: 1.629e-06  Data: 0.013 (0.019)
Train: 7 [ 300/1906 ( 16%)]  Loss: 3.024 (2.93)  Time: 1.532s,  438.54/s  (1.521s,  441.78/s)  LR: 1.629e-06  Data: 0.013 (0.018)
Train: 7 [ 350/1906 ( 18%)]  Loss: 2.880 (2.93)  Time: 1.537s,  437.25/s  (1.523s,  441.11/s)  LR: 1.629e-06  Data: 0.013 (0.018)
Train: 7 [ 400/1906 ( 21%)]  Loss: 2.894 (2.92)  Time: 1.509s,  445.43/s  (1.524s,  441.07/s)  LR: 1.629e-06  Data: 0.013 (0.017)
Train: 7 [ 450/1906 ( 24%)]  Loss: 2.947 (2.92)  Time: 1.535s,  437.81/s  (1.523s,  441.26/s)  LR: 1.629e-06  Data: 0.014 (0.017)
Train: 7 [ 500/1906 ( 26%)]  Loss: 3.039 (2.93)  Time: 1.538s,  436.89/s  (1.524s,  440.91/s)  LR: 1.629e-06  Data: 0.013 (0.016)
Train: 7 [ 550/1906 ( 29%)]  Loss: 2.785 (2.92)  Time: 1.510s,  445.01/s  (1.524s,  440.92/s)  LR: 1.629e-06  Data: 0.015 (0.016)
Train: 7 [ 600/1906 ( 31%)]  Loss: 2.490 (2.89)  Time: 1.537s,  437.26/s  (1.525s,  440.69/s)  LR: 1.629e-06  Data: 0.013 (0.016)
Train: 7 [ 650/1906 ( 34%)]  Loss: 3.392 (2.92)  Time: 1.508s,  445.50/s  (1.524s,  440.87/s)  LR: 1.629e-06  Data: 0.014 (0.016)
Train: 7 [ 700/1906 ( 37%)]  Loss: 3.223 (2.94)  Time: 1.511s,  444.83/s  (1.523s,  441.15/s)  LR: 1.629e-06  Data: 0.013 (0.016)
Train: 7 [ 750/1906 ( 39%)]  Loss: 3.148 (2.96)  Time: 1.526s,  440.45/s  (1.523s,  441.24/s)  LR: 1.629e-06  Data: 0.014 (0.015)
Train: 7 [ 800/1906 ( 42%)]  Loss: 2.588 (2.94)  Time: 1.531s,  438.79/s  (1.523s,  441.14/s)  LR: 1.629e-06  Data: 0.013 (0.015)
Train: 7 [ 850/1906 ( 45%)]  Loss: 2.691 (2.92)  Time: 1.533s,  438.23/s  (1.524s,  441.03/s)  LR: 1.629e-06  Data: 0.013 (0.015)
Train: 7 [ 900/1906 ( 47%)]  Loss: 2.860 (2.92)  Time: 1.533s,  438.25/s  (1.524s,  440.94/s)  LR: 1.629e-06  Data: 0.014 (0.015)
Train: 7 [ 950/1906 ( 50%)]  Loss: 3.244 (2.94)  Time: 1.529s,  439.40/s  (1.524s,  440.86/s)  LR: 1.629e-06  Data: 0.014 (0.015)
Train: 7 [1000/1906 ( 52%)]  Loss: 3.145 (2.95)  Time: 1.532s,  438.67/s  (1.524s,  440.80/s)  LR: 1.629e-06  Data: 0.013 (0.015)
Train: 7 [1050/1906 ( 55%)]  Loss: 3.009 (2.95)  Time: 1.531s,  439.07/s  (1.525s,  440.75/s)  LR: 1.629e-06  Data: 0.014 (0.015)
Train: 7 [1100/1906 ( 58%)]  Loss: 3.182 (2.96)  Time: 1.512s,  444.42/s  (1.525s,  440.80/s)  LR: 1.629e-06  Data: 0.013 (0.015)
Train: 7 [1150/1906 ( 60%)]  Loss: 3.081 (2.96)  Time: 1.509s,  445.29/s  (1.524s,  440.97/s)  LR: 1.629e-06  Data: 0.014 (0.015)
Train: 7 [1200/1906 ( 63%)]  Loss: 2.785 (2.96)  Time: 1.534s,  437.98/s  (1.524s,  440.93/s)  LR: 1.629e-06  Data: 0.013 (0.015)
Train: 7 [1250/1906 ( 66%)]  Loss: 3.172 (2.96)  Time: 1.510s,  444.99/s  (1.524s,  440.94/s)  LR: 1.629e-06  Data: 0.013 (0.015)
Train: 7 [1300/1906 ( 68%)]  Loss: 2.789 (2.96)  Time: 1.536s,  437.42/s  (1.524s,  441.06/s)  LR: 1.629e-06  Data: 0.013 (0.015)
Train: 7 [1350/1906 ( 71%)]  Loss: 2.778 (2.95)  Time: 1.506s,  446.10/s  (1.524s,  441.05/s)  LR: 1.629e-06  Data: 0.015 (0.015)
Train: 7 [1400/1906 ( 73%)]  Loss: 2.709 (2.94)  Time: 1.516s,  443.37/s  (1.523s,  441.19/s)  LR: 1.629e-06  Data: 0.013 (0.015)
Train: 7 [1450/1906 ( 76%)]  Loss: 2.818 (2.94)  Time: 1.513s,  444.25/s  (1.523s,  441.32/s)  LR: 1.629e-06  Data: 0.014 (0.015)
Train: 7 [1500/1906 ( 79%)]  Loss: 2.704 (2.93)  Time: 1.515s,  443.67/s  (1.522s,  441.44/s)  LR: 1.629e-06  Data: 0.013 (0.014)
Train: 7 [1550/1906 ( 81%)]  Loss: 2.908 (2.93)  Time: 1.510s,  445.00/s  (1.522s,  441.54/s)  LR: 1.629e-06  Data: 0.015 (0.014)
Train: 7 [1600/1906 ( 84%)]  Loss: 3.076 (2.94)  Time: 1.512s,  444.41/s  (1.522s,  441.65/s)  LR: 1.629e-06  Data: 0.013 (0.014)
Train: 7 [1650/1906 ( 87%)]  Loss: 3.031 (2.94)  Time: 1.509s,  445.47/s  (1.521s,  441.73/s)  LR: 1.629e-06  Data: 0.013 (0.014)
Train: 7 [1700/1906 ( 89%)]  Loss: 3.462 (2.95)  Time: 1.508s,  445.49/s  (1.521s,  441.78/s)  LR: 1.629e-06  Data: 0.013 (0.014)
Train: 7 [1750/1906 ( 92%)]  Loss: 3.326 (2.96)  Time: 1.510s,  445.14/s  (1.521s,  441.87/s)  LR: 1.629e-06  Data: 0.016 (0.014)
Train: 7 [1800/1906 ( 94%)]  Loss: 2.909 (2.96)  Time: 1.514s,  443.81/s  (1.521s,  441.94/s)  LR: 1.629e-06  Data: 0.014 (0.014)
Train: 7 [1850/1906 ( 97%)]  Loss: 3.136 (2.97)  Time: 1.508s,  445.53/s  (1.520s,  442.01/s)  LR: 1.629e-06  Data: 0.013 (0.014)
Train: 7 [1900/1906 (100%)]  Loss: 3.165 (2.97)  Time: 1.514s,  443.82/s  (1.520s,  442.07/s)  LR: 1.629e-06  Data: 0.014 (0.014)
Train: 7 [1905/1906 (100%)]  Loss: 3.331 (2.98)  Time: 1.499s,  448.22/s  (1.520s,  442.08/s)  LR: 1.629e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.504 (3.504)  Loss:  0.4932 (0.4932)  Acc@1: 91.6016 (91.6016)  Acc@5: 98.1445 (98.1445)
Test: [  48/48]  Time: 0.771 (0.864)  Loss:  0.5933 (0.9385)  Acc@1: 86.7925 (79.5080)  Acc@5: 97.5236 (94.9820)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-7.pth.tar', 79.5080000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-6.pth.tar', 79.384000078125)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-5.pth.tar', 79.31200005126954)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-2.pth.tar', 79.29000010498046)

Train: 8 [   0/1906 (  0%)]  Loss: 2.788 (2.79)  Time: 3.114s,  215.77/s  (3.114s,  215.77/s)  LR: 1.612e-06  Data: 1.563 (1.563)
Train: 8 [  50/1906 (  3%)]  Loss: 2.768 (2.78)  Time: 1.541s,  436.03/s  (1.555s,  432.04/s)  LR: 1.612e-06  Data: 0.014 (0.044)
Train: 8 [ 100/1906 (  5%)]  Loss: 3.113 (2.89)  Time: 1.537s,  437.26/s  (1.546s,  434.81/s)  LR: 1.612e-06  Data: 0.014 (0.029)
Train: 8 [ 150/1906 (  8%)]  Loss: 2.819 (2.87)  Time: 1.510s,  445.16/s  (1.535s,  437.79/s)  LR: 1.612e-06  Data: 0.013 (0.024)
Train: 8 [ 200/1906 ( 10%)]  Loss: 2.929 (2.88)  Time: 1.538s,  437.04/s  (1.530s,  439.14/s)  LR: 1.612e-06  Data: 0.013 (0.021)
Train: 8 [ 250/1906 ( 13%)]  Loss: 2.586 (2.83)  Time: 1.537s,  437.28/s  (1.530s,  439.27/s)  LR: 1.612e-06  Data: 0.013 (0.020)
Train: 8 [ 300/1906 ( 16%)]  Loss: 3.019 (2.86)  Time: 1.539s,  436.57/s  (1.531s,  439.07/s)  LR: 1.612e-06  Data: 0.014 (0.019)
Train: 8 [ 350/1906 ( 18%)]  Loss: 3.163 (2.90)  Time: 1.510s,  444.89/s  (1.530s,  439.17/s)  LR: 1.612e-06  Data: 0.013 (0.018)
Train: 8 [ 400/1906 ( 21%)]  Loss: 2.787 (2.89)  Time: 1.536s,  437.57/s  (1.530s,  439.28/s)  LR: 1.612e-06  Data: 0.013 (0.017)
Train: 8 [ 450/1906 ( 24%)]  Loss: 2.593 (2.86)  Time: 1.511s,  444.86/s  (1.529s,  439.57/s)  LR: 1.612e-06  Data: 0.014 (0.017)
Train: 8 [ 500/1906 ( 26%)]  Loss: 3.404 (2.91)  Time: 1.512s,  444.53/s  (1.528s,  439.81/s)  LR: 1.612e-06  Data: 0.015 (0.017)
Train: 8 [ 550/1906 ( 29%)]  Loss: 3.309 (2.94)  Time: 1.513s,  444.06/s  (1.527s,  440.19/s)  LR: 1.612e-06  Data: 0.013 (0.016)
Train: 8 [ 600/1906 ( 31%)]  Loss: 2.743 (2.92)  Time: 1.508s,  445.56/s  (1.526s,  440.49/s)  LR: 1.612e-06  Data: 0.014 (0.016)
Train: 8 [ 650/1906 ( 34%)]  Loss: 3.089 (2.94)  Time: 1.537s,  437.21/s  (1.526s,  440.33/s)  LR: 1.612e-06  Data: 0.013 (0.016)
Train: 8 [ 700/1906 ( 37%)]  Loss: 2.795 (2.93)  Time: 1.512s,  444.49/s  (1.525s,  440.55/s)  LR: 1.612e-06  Data: 0.015 (0.016)
Train: 8 [ 750/1906 ( 39%)]  Loss: 2.482 (2.90)  Time: 1.536s,  437.44/s  (1.525s,  440.53/s)  LR: 1.612e-06  Data: 0.013 (0.016)
Train: 8 [ 800/1906 ( 42%)]  Loss: 2.812 (2.89)  Time: 1.511s,  444.86/s  (1.526s,  440.45/s)  LR: 1.612e-06  Data: 0.013 (0.016)
Train: 8 [ 850/1906 ( 45%)]  Loss: 3.150 (2.91)  Time: 1.537s,  437.32/s  (1.526s,  440.34/s)  LR: 1.612e-06  Data: 0.013 (0.015)
Train: 8 [ 900/1906 ( 47%)]  Loss: 3.026 (2.91)  Time: 1.535s,  437.66/s  (1.527s,  440.17/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [ 950/1906 ( 50%)]  Loss: 2.949 (2.92)  Time: 1.512s,  444.56/s  (1.526s,  440.41/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [1000/1906 ( 52%)]  Loss: 2.962 (2.92)  Time: 1.514s,  443.88/s  (1.525s,  440.61/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [1050/1906 ( 55%)]  Loss: 2.967 (2.92)  Time: 1.535s,  437.88/s  (1.525s,  440.69/s)  LR: 1.612e-06  Data: 0.013 (0.015)
Train: 8 [1100/1906 ( 58%)]  Loss: 3.201 (2.93)  Time: 1.537s,  437.14/s  (1.525s,  440.52/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [1150/1906 ( 60%)]  Loss: 3.064 (2.94)  Time: 1.513s,  444.18/s  (1.526s,  440.47/s)  LR: 1.612e-06  Data: 0.013 (0.015)
Train: 8 [1200/1906 ( 63%)]  Loss: 2.843 (2.93)  Time: 1.519s,  442.29/s  (1.525s,  440.64/s)  LR: 1.612e-06  Data: 0.013 (0.015)
Train: 8 [1250/1906 ( 66%)]  Loss: 2.989 (2.94)  Time: 1.513s,  444.20/s  (1.525s,  440.79/s)  LR: 1.612e-06  Data: 0.013 (0.015)
Train: 8 [1300/1906 ( 68%)]  Loss: 3.330 (2.95)  Time: 1.511s,  444.65/s  (1.524s,  440.93/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [1350/1906 ( 71%)]  Loss: 2.986 (2.95)  Time: 1.512s,  444.31/s  (1.524s,  440.89/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [1400/1906 ( 73%)]  Loss: 2.770 (2.95)  Time: 1.512s,  444.41/s  (1.524s,  440.90/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [1450/1906 ( 76%)]  Loss: 2.798 (2.94)  Time: 1.511s,  444.63/s  (1.524s,  441.03/s)  LR: 1.612e-06  Data: 0.013 (0.015)
Train: 8 [1500/1906 ( 79%)]  Loss: 2.886 (2.94)  Time: 1.512s,  444.54/s  (1.523s,  441.14/s)  LR: 1.612e-06  Data: 0.015 (0.015)
Train: 8 [1550/1906 ( 81%)]  Loss: 2.979 (2.94)  Time: 1.509s,  445.38/s  (1.523s,  441.24/s)  LR: 1.612e-06  Data: 0.013 (0.015)
Train: 8 [1600/1906 ( 84%)]  Loss: 3.270 (2.95)  Time: 1.511s,  444.70/s  (1.523s,  441.31/s)  LR: 1.612e-06  Data: 0.013 (0.015)
Train: 8 [1650/1906 ( 87%)]  Loss: 2.827 (2.95)  Time: 1.520s,  442.19/s  (1.522s,  441.40/s)  LR: 1.612e-06  Data: 0.019 (0.015)
Train: 8 [1700/1906 ( 89%)]  Loss: 3.041 (2.95)  Time: 1.534s,  438.01/s  (1.523s,  441.36/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [1750/1906 ( 92%)]  Loss: 2.988 (2.95)  Time: 1.510s,  445.11/s  (1.523s,  441.36/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [1800/1906 ( 94%)]  Loss: 3.260 (2.96)  Time: 1.512s,  444.47/s  (1.522s,  441.45/s)  LR: 1.612e-06  Data: 0.013 (0.015)
Train: 8 [1850/1906 ( 97%)]  Loss: 3.163 (2.96)  Time: 1.513s,  444.02/s  (1.522s,  441.53/s)  LR: 1.612e-06  Data: 0.014 (0.015)
Train: 8 [1900/1906 (100%)]  Loss: 3.487 (2.98)  Time: 1.536s,  437.62/s  (1.522s,  441.43/s)  LR: 1.612e-06  Data: 0.014 (0.014)
Train: 8 [1905/1906 (100%)]  Loss: 3.209 (2.98)  Time: 1.524s,  440.92/s  (1.522s,  441.43/s)  LR: 1.612e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.649 (3.649)  Loss:  0.5283 (0.5283)  Acc@1: 91.7969 (91.7969)  Acc@5: 98.0469 (98.0469)
Test: [  48/48]  Time: 0.771 (0.867)  Loss:  0.6221 (0.9732)  Acc@1: 87.2642 (79.3960)  Acc@5: 97.5236 (94.9340)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-7.pth.tar', 79.5080000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-8.pth.tar', 79.39600002685548)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-6.pth.tar', 79.384000078125)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-5.pth.tar', 79.31200005126954)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-2.pth.tar', 79.29000010498046)

Train: 9 [   0/1906 (  0%)]  Loss: 3.097 (3.10)  Time: 3.092s,  217.33/s  (3.092s,  217.33/s)  LR: 1.593e-06  Data: 1.592 (1.592)
Train: 9 [  50/1906 (  3%)]  Loss: 3.106 (3.10)  Time: 1.507s,  445.77/s  (1.542s,  435.85/s)  LR: 1.593e-06  Data: 0.014 (0.044)
Train: 9 [ 100/1906 (  5%)]  Loss: 2.955 (3.05)  Time: 1.511s,  444.62/s  (1.530s,  439.11/s)  LR: 1.593e-06  Data: 0.014 (0.029)
Train: 9 [ 150/1906 (  8%)]  Loss: 3.409 (3.14)  Time: 1.510s,  445.12/s  (1.524s,  441.00/s)  LR: 1.593e-06  Data: 0.014 (0.024)
Train: 9 [ 200/1906 ( 10%)]  Loss: 2.684 (3.05)  Time: 1.511s,  444.65/s  (1.521s,  441.76/s)  LR: 1.593e-06  Data: 0.013 (0.021)
Train: 9 [ 250/1906 ( 13%)]  Loss: 3.247 (3.08)  Time: 1.506s,  446.21/s  (1.519s,  442.38/s)  LR: 1.593e-06  Data: 0.014 (0.020)
Train: 9 [ 300/1906 ( 16%)]  Loss: 2.702 (3.03)  Time: 1.533s,  438.31/s  (1.519s,  442.50/s)  LR: 1.593e-06  Data: 0.013 (0.019)
Train: 9 [ 350/1906 ( 18%)]  Loss: 2.741 (2.99)  Time: 1.537s,  437.19/s  (1.520s,  442.19/s)  LR: 1.593e-06  Data: 0.012 (0.018)
Train: 9 [ 400/1906 ( 21%)]  Loss: 2.944 (2.99)  Time: 1.513s,  444.26/s  (1.520s,  442.21/s)  LR: 1.593e-06  Data: 0.013 (0.017)
Train: 9 [ 450/1906 ( 24%)]  Loss: 2.841 (2.97)  Time: 1.511s,  444.65/s  (1.519s,  442.49/s)  LR: 1.593e-06  Data: 0.014 (0.017)
Train: 9 [ 500/1906 ( 26%)]  Loss: 2.957 (2.97)  Time: 1.512s,  444.49/s  (1.518s,  442.72/s)  LR: 1.593e-06  Data: 0.013 (0.017)
Train: 9 [ 550/1906 ( 29%)]  Loss: 2.965 (2.97)  Time: 1.535s,  437.69/s  (1.519s,  442.45/s)  LR: 1.593e-06  Data: 0.014 (0.016)
Train: 9 [ 600/1906 ( 31%)]  Loss: 3.053 (2.98)  Time: 1.539s,  436.69/s  (1.520s,  442.00/s)  LR: 1.593e-06  Data: 0.013 (0.016)
Train: 9 [ 650/1906 ( 34%)]  Loss: 2.626 (2.95)  Time: 1.533s,  438.27/s  (1.522s,  441.64/s)  LR: 1.593e-06  Data: 0.013 (0.016)
Train: 9 [ 700/1906 ( 37%)]  Loss: 3.052 (2.96)  Time: 1.510s,  445.18/s  (1.521s,  441.88/s)  LR: 1.593e-06  Data: 0.013 (0.016)
Train: 9 [ 750/1906 ( 39%)]  Loss: 3.047 (2.96)  Time: 1.510s,  444.92/s  (1.520s,  442.09/s)  LR: 1.593e-06  Data: 0.013 (0.016)
Train: 9 [ 800/1906 ( 42%)]  Loss: 2.811 (2.96)  Time: 1.514s,  443.99/s  (1.519s,  442.28/s)  LR: 1.593e-06  Data: 0.014 (0.016)
Train: 9 [ 850/1906 ( 45%)]  Loss: 2.884 (2.95)  Time: 1.527s,  439.97/s  (1.519s,  442.31/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [ 900/1906 ( 47%)]  Loss: 2.918 (2.95)  Time: 1.526s,  440.28/s  (1.520s,  442.15/s)  LR: 1.593e-06  Data: 0.013 (0.015)
Train: 9 [ 950/1906 ( 50%)]  Loss: 3.445 (2.97)  Time: 1.529s,  439.39/s  (1.520s,  442.01/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1000/1906 ( 52%)]  Loss: 2.940 (2.97)  Time: 1.527s,  440.03/s  (1.521s,  441.88/s)  LR: 1.593e-06  Data: 0.013 (0.015)
Train: 9 [1050/1906 ( 55%)]  Loss: 2.954 (2.97)  Time: 1.519s,  442.42/s  (1.521s,  441.88/s)  LR: 1.593e-06  Data: 0.021 (0.015)
Train: 9 [1100/1906 ( 58%)]  Loss: 2.762 (2.96)  Time: 1.511s,  444.68/s  (1.521s,  441.95/s)  LR: 1.593e-06  Data: 0.013 (0.015)
Train: 9 [1150/1906 ( 60%)]  Loss: 3.110 (2.97)  Time: 1.539s,  436.74/s  (1.521s,  441.94/s)  LR: 1.593e-06  Data: 0.013 (0.015)
Train: 9 [1200/1906 ( 63%)]  Loss: 3.316 (2.98)  Time: 1.531s,  438.83/s  (1.521s,  441.94/s)  LR: 1.593e-06  Data: 0.013 (0.015)
Train: 9 [1250/1906 ( 66%)]  Loss: 2.980 (2.98)  Time: 1.529s,  439.53/s  (1.521s,  441.93/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1300/1906 ( 68%)]  Loss: 2.896 (2.98)  Time: 1.510s,  444.94/s  (1.521s,  441.94/s)  LR: 1.593e-06  Data: 0.013 (0.015)
Train: 9 [1350/1906 ( 71%)]  Loss: 2.742 (2.97)  Time: 1.509s,  445.32/s  (1.520s,  442.03/s)  LR: 1.593e-06  Data: 0.013 (0.015)
Train: 9 [1400/1906 ( 73%)]  Loss: 3.424 (2.99)  Time: 1.508s,  445.53/s  (1.520s,  442.13/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1450/1906 ( 76%)]  Loss: 2.979 (2.99)  Time: 1.510s,  444.92/s  (1.520s,  442.18/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1500/1906 ( 79%)]  Loss: 2.907 (2.98)  Time: 1.508s,  445.49/s  (1.520s,  442.24/s)  LR: 1.593e-06  Data: 0.013 (0.015)
Train: 9 [1550/1906 ( 81%)]  Loss: 3.512 (3.00)  Time: 1.506s,  446.13/s  (1.519s,  442.31/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1600/1906 ( 84%)]  Loss: 2.888 (3.00)  Time: 1.507s,  446.04/s  (1.519s,  442.39/s)  LR: 1.593e-06  Data: 0.013 (0.015)
Train: 9 [1650/1906 ( 87%)]  Loss: 2.863 (2.99)  Time: 1.510s,  444.96/s  (1.519s,  442.45/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1700/1906 ( 89%)]  Loss: 2.423 (2.98)  Time: 1.538s,  437.01/s  (1.519s,  442.50/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1750/1906 ( 92%)]  Loss: 3.176 (2.98)  Time: 1.515s,  443.55/s  (1.518s,  442.57/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1800/1906 ( 94%)]  Loss: 2.750 (2.98)  Time: 1.510s,  445.04/s  (1.518s,  442.63/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1850/1906 ( 97%)]  Loss: 2.968 (2.98)  Time: 1.511s,  444.80/s  (1.518s,  442.69/s)  LR: 1.593e-06  Data: 0.014 (0.015)
Train: 9 [1900/1906 (100%)]  Loss: 2.791 (2.97)  Time: 1.508s,  445.69/s  (1.518s,  442.73/s)  LR: 1.593e-06  Data: 0.014 (0.014)
Train: 9 [1905/1906 (100%)]  Loss: 3.229 (2.98)  Time: 1.494s,  449.90/s  (1.518s,  442.74/s)  LR: 1.593e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.500 (3.500)  Loss:  0.5225 (0.5225)  Acc@1: 91.6992 (91.6992)  Acc@5: 98.0469 (98.0469)
Test: [  48/48]  Time: 0.772 (0.864)  Loss:  0.6118 (0.9644)  Acc@1: 87.6179 (79.3900)  Acc@5: 97.6415 (94.9520)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-7.pth.tar', 79.5080000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-8.pth.tar', 79.39600002685548)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-9.pth.tar', 79.39000005126952)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-6.pth.tar', 79.384000078125)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-5.pth.tar', 79.31200005126954)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-2.pth.tar', 79.29000010498046)

Train: 10 [   0/1906 (  0%)]  Loss: 2.994 (2.99)  Time: 2.909s,  230.98/s  (2.909s,  230.98/s)  LR: 1.572e-06  Data: 1.330 (1.330)
Train: 10 [  50/1906 (  3%)]  Loss: 2.875 (2.93)  Time: 1.514s,  443.95/s  (1.549s,  433.77/s)  LR: 1.572e-06  Data: 0.013 (0.039)
Train: 10 [ 100/1906 (  5%)]  Loss: 2.891 (2.92)  Time: 1.539s,  436.51/s  (1.537s,  437.34/s)  LR: 1.572e-06  Data: 0.013 (0.026)
Train: 10 [ 150/1906 (  8%)]  Loss: 3.159 (2.98)  Time: 1.536s,  437.48/s  (1.536s,  437.47/s)  LR: 1.572e-06  Data: 0.013 (0.022)
Train: 10 [ 200/1906 ( 10%)]  Loss: 3.342 (3.05)  Time: 1.538s,  437.01/s  (1.537s,  437.33/s)  LR: 1.572e-06  Data: 0.013 (0.020)
Train: 10 [ 250/1906 ( 13%)]  Loss: 3.371 (3.11)  Time: 1.512s,  444.52/s  (1.535s,  437.88/s)  LR: 1.572e-06  Data: 0.013 (0.019)
Train: 10 [ 300/1906 ( 16%)]  Loss: 3.007 (3.09)  Time: 1.512s,  444.43/s  (1.531s,  439.01/s)  LR: 1.572e-06  Data: 0.013 (0.018)
Train: 10 [ 350/1906 ( 18%)]  Loss: 2.877 (3.06)  Time: 1.513s,  444.04/s  (1.528s,  439.85/s)  LR: 1.572e-06  Data: 0.013 (0.017)
Train: 10 [ 400/1906 ( 21%)]  Loss: 2.806 (3.04)  Time: 1.510s,  444.96/s  (1.526s,  440.47/s)  LR: 1.572e-06  Data: 0.013 (0.017)
Train: 10 [ 450/1906 ( 24%)]  Loss: 3.217 (3.05)  Time: 1.507s,  445.89/s  (1.524s,  440.94/s)  LR: 1.572e-06  Data: 0.013 (0.016)
Train: 10 [ 500/1906 ( 26%)]  Loss: 2.531 (3.01)  Time: 1.514s,  443.92/s  (1.523s,  441.31/s)  LR: 1.572e-06  Data: 0.014 (0.016)
Train: 10 [ 550/1906 ( 29%)]  Loss: 2.823 (2.99)  Time: 1.514s,  443.77/s  (1.522s,  441.60/s)  LR: 1.572e-06  Data: 0.013 (0.016)
Train: 10 [ 600/1906 ( 31%)]  Loss: 3.107 (3.00)  Time: 1.509s,  445.26/s  (1.521s,  441.85/s)  LR: 1.572e-06  Data: 0.014 (0.016)
Train: 10 [ 650/1906 ( 34%)]  Loss: 2.882 (2.99)  Time: 1.511s,  444.75/s  (1.520s,  442.07/s)  LR: 1.572e-06  Data: 0.013 (0.015)
Train: 10 [ 700/1906 ( 37%)]  Loss: 2.892 (2.99)  Time: 1.507s,  445.84/s  (1.520s,  442.24/s)  LR: 1.572e-06  Data: 0.013 (0.015)
Train: 10 [ 750/1906 ( 39%)]  Loss: 2.845 (2.98)  Time: 1.512s,  444.50/s  (1.519s,  442.41/s)  LR: 1.572e-06  Data: 0.013 (0.015)
Train: 10 [ 800/1906 ( 42%)]  Loss: 2.867 (2.97)  Time: 1.531s,  438.86/s  (1.520s,  442.23/s)  LR: 1.572e-06  Data: 0.013 (0.015)
Train: 10 [ 850/1906 ( 45%)]  Loss: 2.982 (2.97)  Time: 1.524s,  440.89/s  (1.520s,  442.07/s)  LR: 1.572e-06  Data: 0.014 (0.015)
Train: 10 [ 900/1906 ( 47%)]  Loss: 2.886 (2.97)  Time: 1.533s,  438.38/s  (1.521s,  441.94/s)  LR: 1.572e-06  Data: 0.013 (0.015)
Train: 10 [ 950/1906 ( 50%)]  Loss: 3.028 (2.97)  Time: 1.534s,  438.16/s  (1.521s,  441.81/s)  LR: 1.572e-06  Data: 0.013 (0.015)
Train: 10 [1000/1906 ( 52%)]  Loss: 2.919 (2.97)  Time: 1.526s,  440.46/s  (1.521s,  441.67/s)  LR: 1.572e-06  Data: 0.013 (0.015)
Train: 10 [1050/1906 ( 55%)]  Loss: 2.723 (2.96)  Time: 1.534s,  438.10/s  (1.522s,  441.57/s)  LR: 1.572e-06  Data: 0.014 (0.015)
Train: 10 [1100/1906 ( 58%)]  Loss: 2.873 (2.95)  Time: 1.531s,  438.99/s  (1.522s,  441.48/s)  LR: 1.572e-06  Data: 0.013 (0.015)
Train: 10 [1150/1906 ( 60%)]  Loss: 2.691 (2.94)  Time: 1.526s,  440.29/s  (1.522s,  441.39/s)  LR: 1.572e-06  Data: 0.013 (0.015)
Train: 10 [1200/1906 ( 63%)]  Loss: 3.022 (2.94)  Time: 1.538s,  437.05/s  (1.522s,  441.46/s)  LR: 1.572e-06  Data: 0.013 (0.014)
Train: 10 [1250/1906 ( 66%)]  Loss: 2.757 (2.94)  Time: 1.527s,  439.99/s  (1.522s,  441.43/s)  LR: 1.572e-06  Data: 0.014 (0.014)
Train: 10 [1300/1906 ( 68%)]  Loss: 2.968 (2.94)  Time: 1.527s,  439.95/s  (1.522s,  441.43/s)  LR: 1.572e-06  Data: 0.013 (0.014)
Train: 10 [1350/1906 ( 71%)]  Loss: 3.539 (2.96)  Time: 1.525s,  440.66/s  (1.523s,  441.33/s)  LR: 1.572e-06  Data: 0.020 (0.014)
Train: 10 [1400/1906 ( 73%)]  Loss: 2.789 (2.95)  Time: 1.519s,  442.29/s  (1.523s,  441.33/s)  LR: 1.572e-06  Data: 0.013 (0.014)
Train: 10 [1450/1906 ( 76%)]  Loss: 2.940 (2.95)  Time: 1.510s,  445.16/s  (1.522s,  441.44/s)  LR: 1.572e-06  Data: 0.013 (0.014)
Train: 10 [1500/1906 ( 79%)]  Loss: 3.158 (2.96)  Time: 1.534s,  438.02/s  (1.522s,  441.42/s)  LR: 1.572e-06  Data: 0.013 (0.014)
Train: 10 [1550/1906 ( 81%)]  Loss: 2.610 (2.95)  Time: 1.539s,  436.74/s  (1.523s,  441.29/s)  LR: 1.572e-06  Data: 0.013 (0.014)
Train: 10 [1600/1906 ( 84%)]  Loss: 3.574 (2.97)  Time: 1.514s,  443.81/s  (1.523s,  441.37/s)  LR: 1.572e-06  Data: 0.014 (0.014)
Train: 10 [1650/1906 ( 87%)]  Loss: 2.919 (2.97)  Time: 1.539s,  436.72/s  (1.523s,  441.30/s)  LR: 1.572e-06  Data: 0.014 (0.014)
Train: 10 [1700/1906 ( 89%)]  Loss: 3.013 (2.97)  Time: 1.536s,  437.39/s  (1.523s,  441.17/s)  LR: 1.572e-06  Data: 0.013 (0.014)
Train: 10 [1750/1906 ( 92%)]  Loss: 3.264 (2.98)  Time: 1.510s,  445.13/s  (1.523s,  441.25/s)  LR: 1.572e-06  Data: 0.014 (0.014)
Train: 10 [1800/1906 ( 94%)]  Loss: 2.908 (2.97)  Time: 1.507s,  445.92/s  (1.523s,  441.34/s)  LR: 1.572e-06  Data: 0.014 (0.014)
Train: 10 [1850/1906 ( 97%)]  Loss: 2.759 (2.97)  Time: 1.512s,  444.33/s  (1.523s,  441.33/s)  LR: 1.572e-06  Data: 0.014 (0.014)
Train: 10 [1900/1906 (100%)]  Loss: 3.148 (2.97)  Time: 1.539s,  436.57/s  (1.523s,  441.30/s)  LR: 1.572e-06  Data: 0.013 (0.014)
Train: 10 [1905/1906 (100%)]  Loss: 3.056 (2.98)  Time: 1.515s,  443.63/s  (1.523s,  441.30/s)  LR: 1.572e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.545 (3.545)  Loss:  0.5142 (0.5142)  Acc@1: 91.6992 (91.6992)  Acc@5: 97.8516 (97.8516)
Test: [  48/48]  Time: 0.775 (0.865)  Loss:  0.6021 (0.9587)  Acc@1: 87.7359 (79.4140)  Acc@5: 97.8774 (94.9520)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-7.pth.tar', 79.5080000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-10.pth.tar', 79.41400010253906)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-8.pth.tar', 79.39600002685548)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-9.pth.tar', 79.39000005126952)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-6.pth.tar', 79.384000078125)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-5.pth.tar', 79.31200005126954)

Train: 11 [   0/1906 (  0%)]  Loss: 2.940 (2.94)  Time: 2.935s,  228.94/s  (2.935s,  228.94/s)  LR: 1.549e-06  Data: 1.460 (1.460)
Train: 11 [  50/1906 (  3%)]  Loss: 2.945 (2.94)  Time: 1.507s,  445.95/s  (1.539s,  436.51/s)  LR: 1.549e-06  Data: 0.013 (0.042)
Train: 11 [ 100/1906 (  5%)]  Loss: 3.416 (3.10)  Time: 1.507s,  445.89/s  (1.530s,  439.23/s)  LR: 1.549e-06  Data: 0.014 (0.028)
Train: 11 [ 150/1906 (  8%)]  Loss: 3.196 (3.12)  Time: 1.512s,  444.36/s  (1.524s,  440.93/s)  LR: 1.549e-06  Data: 0.013 (0.023)
Train: 11 [ 200/1906 ( 10%)]  Loss: 2.591 (3.02)  Time: 1.537s,  437.30/s  (1.525s,  440.57/s)  LR: 1.549e-06  Data: 0.013 (0.020)
Train: 11 [ 250/1906 ( 13%)]  Loss: 3.407 (3.08)  Time: 1.534s,  438.19/s  (1.527s,  440.01/s)  LR: 1.549e-06  Data: 0.013 (0.019)
Train: 11 [ 300/1906 ( 16%)]  Loss: 3.001 (3.07)  Time: 1.533s,  438.30/s  (1.528s,  439.65/s)  LR: 1.549e-06  Data: 0.013 (0.018)
Train: 11 [ 350/1906 ( 18%)]  Loss: 3.159 (3.08)  Time: 1.512s,  444.47/s  (1.526s,  440.26/s)  LR: 1.549e-06  Data: 0.013 (0.017)
Train: 11 [ 400/1906 ( 21%)]  Loss: 2.736 (3.04)  Time: 1.538s,  436.98/s  (1.527s,  440.09/s)  LR: 1.549e-06  Data: 0.014 (0.017)
Train: 11 [ 450/1906 ( 24%)]  Loss: 3.200 (3.06)  Time: 1.539s,  436.65/s  (1.528s,  439.76/s)  LR: 1.549e-06  Data: 0.013 (0.016)
Train: 11 [ 500/1906 ( 26%)]  Loss: 2.868 (3.04)  Time: 1.512s,  444.43/s  (1.527s,  440.05/s)  LR: 1.549e-06  Data: 0.013 (0.016)
Train: 11 [ 550/1906 ( 29%)]  Loss: 2.795 (3.02)  Time: 1.512s,  444.40/s  (1.526s,  440.47/s)  LR: 1.549e-06  Data: 0.013 (0.016)
Train: 11 [ 600/1906 ( 31%)]  Loss: 2.876 (3.01)  Time: 1.534s,  438.07/s  (1.526s,  440.44/s)  LR: 1.549e-06  Data: 0.014 (0.016)
Train: 11 [ 650/1906 ( 34%)]  Loss: 2.833 (3.00)  Time: 1.537s,  437.23/s  (1.527s,  440.17/s)  LR: 1.549e-06  Data: 0.012 (0.016)
Train: 11 [ 700/1906 ( 37%)]  Loss: 3.124 (3.01)  Time: 1.536s,  437.45/s  (1.527s,  439.95/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [ 750/1906 ( 39%)]  Loss: 2.973 (3.00)  Time: 1.540s,  436.44/s  (1.528s,  439.76/s)  LR: 1.549e-06  Data: 0.014 (0.015)
Train: 11 [ 800/1906 ( 42%)]  Loss: 3.249 (3.02)  Time: 1.533s,  438.31/s  (1.529s,  439.60/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [ 850/1906 ( 45%)]  Loss: 2.802 (3.01)  Time: 1.539s,  436.61/s  (1.529s,  439.44/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [ 900/1906 ( 47%)]  Loss: 2.853 (3.00)  Time: 1.537s,  437.35/s  (1.530s,  439.32/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [ 950/1906 ( 50%)]  Loss: 3.111 (3.00)  Time: 1.512s,  444.39/s  (1.529s,  439.58/s)  LR: 1.549e-06  Data: 0.014 (0.015)
Train: 11 [1000/1906 ( 52%)]  Loss: 3.251 (3.02)  Time: 1.537s,  437.09/s  (1.529s,  439.49/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [1050/1906 ( 55%)]  Loss: 2.829 (3.01)  Time: 1.538s,  436.82/s  (1.529s,  439.38/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [1100/1906 ( 58%)]  Loss: 2.783 (3.00)  Time: 1.537s,  437.35/s  (1.530s,  439.28/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [1150/1906 ( 60%)]  Loss: 2.911 (2.99)  Time: 1.539s,  436.76/s  (1.530s,  439.18/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [1200/1906 ( 63%)]  Loss: 2.964 (2.99)  Time: 1.506s,  446.20/s  (1.529s,  439.41/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [1250/1906 ( 66%)]  Loss: 3.407 (3.01)  Time: 1.509s,  445.23/s  (1.529s,  439.53/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [1300/1906 ( 68%)]  Loss: 3.176 (3.01)  Time: 1.509s,  445.46/s  (1.529s,  439.59/s)  LR: 1.549e-06  Data: 0.013 (0.015)
Train: 11 [1350/1906 ( 71%)]  Loss: 3.221 (3.02)  Time: 1.512s,  444.40/s  (1.528s,  439.78/s)  LR: 1.549e-06  Data: 0.013 (0.014)
Train: 11 [1400/1906 ( 73%)]  Loss: 2.703 (3.01)  Time: 1.507s,  445.86/s  (1.528s,  439.90/s)  LR: 1.549e-06  Data: 0.013 (0.014)
Train: 11 [1450/1906 ( 76%)]  Loss: 3.143 (3.02)  Time: 1.534s,  437.97/s  (1.527s,  440.00/s)  LR: 1.549e-06  Data: 0.013 (0.014)
Train: 11 [1500/1906 ( 79%)]  Loss: 2.861 (3.01)  Time: 1.537s,  437.21/s  (1.528s,  439.91/s)  LR: 1.549e-06  Data: 0.014 (0.014)
Train: 11 [1550/1906 ( 81%)]  Loss: 2.946 (3.01)  Time: 1.537s,  437.16/s  (1.528s,  439.82/s)  LR: 1.549e-06  Data: 0.013 (0.014)
Train: 11 [1600/1906 ( 84%)]  Loss: 2.820 (3.00)  Time: 1.522s,  441.56/s  (1.528s,  439.87/s)  LR: 1.549e-06  Data: 0.022 (0.014)
Train: 11 [1650/1906 ( 87%)]  Loss: 2.406 (2.99)  Time: 1.513s,  444.01/s  (1.527s,  440.01/s)  LR: 1.549e-06  Data: 0.014 (0.014)
Train: 11 [1700/1906 ( 89%)]  Loss: 3.221 (2.99)  Time: 1.506s,  446.28/s  (1.527s,  440.15/s)  LR: 1.549e-06  Data: 0.013 (0.014)
Train: 11 [1750/1906 ( 92%)]  Loss: 3.224 (3.00)  Time: 1.512s,  444.57/s  (1.526s,  440.28/s)  LR: 1.549e-06  Data: 0.013 (0.014)
Train: 11 [1800/1906 ( 94%)]  Loss: 2.852 (2.99)  Time: 1.533s,  438.31/s  (1.526s,  440.39/s)  LR: 1.549e-06  Data: 0.013 (0.014)
Train: 11 [1850/1906 ( 97%)]  Loss: 2.681 (2.99)  Time: 1.535s,  437.84/s  (1.526s,  440.35/s)  LR: 1.549e-06  Data: 0.013 (0.014)
Train: 11 [1900/1906 (100%)]  Loss: 3.162 (2.99)  Time: 1.509s,  445.36/s  (1.526s,  440.36/s)  LR: 1.549e-06  Data: 0.013 (0.014)
Train: 11 [1905/1906 (100%)]  Loss: 3.020 (2.99)  Time: 1.493s,  450.08/s  (1.526s,  440.37/s)  LR: 1.549e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.675 (3.675)  Loss:  0.5381 (0.5381)  Acc@1: 91.7969 (91.7969)  Acc@5: 98.1445 (98.1445)
Test: [  48/48]  Time: 0.772 (0.869)  Loss:  0.6313 (0.9838)  Acc@1: 86.7924 (79.4080)  Acc@5: 97.5236 (94.8940)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-7.pth.tar', 79.5080000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-10.pth.tar', 79.41400010253906)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-11.pth.tar', 79.40799995117187)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-8.pth.tar', 79.39600002685548)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-9.pth.tar', 79.39000005126952)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-6.pth.tar', 79.384000078125)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-1.pth.tar', 79.3200000024414)

Train: 12 [   0/1906 (  0%)]  Loss: 3.125 (3.12)  Time: 2.985s,  225.16/s  (2.985s,  225.16/s)  LR: 1.524e-06  Data: 1.382 (1.382)
Train: 12 [  50/1906 (  3%)]  Loss: 2.774 (2.95)  Time: 1.507s,  445.79/s  (1.543s,  435.56/s)  LR: 1.524e-06  Data: 0.013 (0.041)
Train: 12 [ 100/1906 (  5%)]  Loss: 3.127 (3.01)  Time: 1.516s,  443.28/s  (1.529s,  439.60/s)  LR: 1.524e-06  Data: 0.013 (0.027)
Train: 12 [ 150/1906 (  8%)]  Loss: 2.736 (2.94)  Time: 1.507s,  446.05/s  (1.524s,  440.89/s)  LR: 1.524e-06  Data: 0.014 (0.023)
Train: 12 [ 200/1906 ( 10%)]  Loss: 2.871 (2.93)  Time: 1.516s,  443.38/s  (1.522s,  441.50/s)  LR: 1.524e-06  Data: 0.013 (0.020)
Train: 12 [ 250/1906 ( 13%)]  Loss: 3.267 (2.98)  Time: 1.506s,  446.08/s  (1.520s,  442.16/s)  LR: 1.524e-06  Data: 0.013 (0.019)
Train: 12 [ 300/1906 ( 16%)]  Loss: 3.160 (3.01)  Time: 1.512s,  444.31/s  (1.518s,  442.63/s)  LR: 1.524e-06  Data: 0.014 (0.018)
Train: 12 [ 350/1906 ( 18%)]  Loss: 2.858 (2.99)  Time: 1.506s,  446.24/s  (1.518s,  442.74/s)  LR: 1.524e-06  Data: 0.013 (0.017)
Train: 12 [ 400/1906 ( 21%)]  Loss: 2.670 (2.95)  Time: 1.507s,  445.96/s  (1.517s,  443.05/s)  LR: 1.524e-06  Data: 0.013 (0.017)
Train: 12 [ 450/1906 ( 24%)]  Loss: 2.928 (2.95)  Time: 1.537s,  437.30/s  (1.517s,  442.91/s)  LR: 1.524e-06  Data: 0.013 (0.017)
Train: 12 [ 500/1906 ( 26%)]  Loss: 2.764 (2.93)  Time: 1.536s,  437.37/s  (1.519s,  442.39/s)  LR: 1.524e-06  Data: 0.013 (0.016)
Train: 12 [ 550/1906 ( 29%)]  Loss: 3.045 (2.94)  Time: 1.531s,  438.83/s  (1.520s,  442.06/s)  LR: 1.524e-06  Data: 0.014 (0.016)
Train: 12 [ 600/1906 ( 31%)]  Loss: 2.886 (2.94)  Time: 1.508s,  445.74/s  (1.519s,  442.30/s)  LR: 1.524e-06  Data: 0.013 (0.016)
Train: 12 [ 650/1906 ( 34%)]  Loss: 2.970 (2.94)  Time: 1.508s,  445.69/s  (1.519s,  442.51/s)  LR: 1.524e-06  Data: 0.013 (0.016)
Train: 12 [ 700/1906 ( 37%)]  Loss: 3.179 (2.96)  Time: 1.506s,  446.27/s  (1.518s,  442.72/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [ 750/1906 ( 39%)]  Loss: 2.920 (2.95)  Time: 1.513s,  444.27/s  (1.517s,  442.87/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [ 800/1906 ( 42%)]  Loss: 3.187 (2.97)  Time: 1.510s,  444.98/s  (1.517s,  443.01/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [ 850/1906 ( 45%)]  Loss: 3.377 (2.99)  Time: 1.535s,  437.86/s  (1.517s,  442.88/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [ 900/1906 ( 47%)]  Loss: 2.878 (2.99)  Time: 1.509s,  445.27/s  (1.517s,  442.85/s)  LR: 1.524e-06  Data: 0.014 (0.015)
Train: 12 [ 950/1906 ( 50%)]  Loss: 3.067 (2.99)  Time: 1.509s,  445.35/s  (1.517s,  442.96/s)  LR: 1.524e-06  Data: 0.014 (0.015)
Train: 12 [1000/1906 ( 52%)]  Loss: 2.959 (2.99)  Time: 1.507s,  445.97/s  (1.517s,  442.92/s)  LR: 1.524e-06  Data: 0.014 (0.015)
Train: 12 [1050/1906 ( 55%)]  Loss: 2.860 (2.98)  Time: 1.527s,  440.09/s  (1.517s,  442.94/s)  LR: 1.524e-06  Data: 0.014 (0.015)
Train: 12 [1100/1906 ( 58%)]  Loss: 3.023 (2.98)  Time: 1.512s,  444.55/s  (1.517s,  442.96/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [1150/1906 ( 60%)]  Loss: 3.023 (2.99)  Time: 1.508s,  445.57/s  (1.517s,  443.05/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [1200/1906 ( 63%)]  Loss: 2.913 (2.98)  Time: 1.508s,  445.64/s  (1.516s,  443.13/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [1250/1906 ( 66%)]  Loss: 2.703 (2.97)  Time: 1.503s,  447.01/s  (1.516s,  443.20/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [1300/1906 ( 68%)]  Loss: 3.132 (2.98)  Time: 1.503s,  446.99/s  (1.516s,  443.27/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [1350/1906 ( 71%)]  Loss: 2.612 (2.96)  Time: 1.509s,  445.32/s  (1.516s,  443.33/s)  LR: 1.524e-06  Data: 0.014 (0.015)
Train: 12 [1400/1906 ( 73%)]  Loss: 2.183 (2.94)  Time: 1.509s,  445.41/s  (1.516s,  443.39/s)  LR: 1.524e-06  Data: 0.013 (0.015)
Train: 12 [1450/1906 ( 76%)]  Loss: 3.599 (2.96)  Time: 1.508s,  445.61/s  (1.515s,  443.44/s)  LR: 1.524e-06  Data: 0.014 (0.015)
Train: 12 [1500/1906 ( 79%)]  Loss: 3.204 (2.97)  Time: 1.506s,  446.29/s  (1.515s,  443.50/s)  LR: 1.524e-06  Data: 0.013 (0.014)
Train: 12 [1550/1906 ( 81%)]  Loss: 2.805 (2.96)  Time: 1.505s,  446.49/s  (1.515s,  443.55/s)  LR: 1.524e-06  Data: 0.013 (0.014)
Train: 12 [1600/1906 ( 84%)]  Loss: 2.858 (2.96)  Time: 1.510s,  445.02/s  (1.515s,  443.59/s)  LR: 1.524e-06  Data: 0.013 (0.014)
Train: 12 [1650/1906 ( 87%)]  Loss: 3.093 (2.96)  Time: 1.510s,  444.90/s  (1.515s,  443.63/s)  LR: 1.524e-06  Data: 0.013 (0.014)
Train: 12 [1700/1906 ( 89%)]  Loss: 3.252 (2.97)  Time: 1.508s,  445.71/s  (1.515s,  443.67/s)  LR: 1.524e-06  Data: 0.013 (0.014)
Train: 12 [1750/1906 ( 92%)]  Loss: 3.290 (2.98)  Time: 1.506s,  446.15/s  (1.515s,  443.71/s)  LR: 1.524e-06  Data: 0.013 (0.014)
Train: 12 [1800/1906 ( 94%)]  Loss: 3.269 (2.99)  Time: 1.504s,  446.84/s  (1.514s,  443.75/s)  LR: 1.524e-06  Data: 0.014 (0.014)
Train: 12 [1850/1906 ( 97%)]  Loss: 3.067 (2.99)  Time: 1.507s,  446.05/s  (1.514s,  443.72/s)  LR: 1.524e-06  Data: 0.014 (0.014)
Train: 12 [1900/1906 (100%)]  Loss: 2.862 (2.99)  Time: 1.508s,  445.48/s  (1.514s,  443.75/s)  LR: 1.524e-06  Data: 0.013 (0.014)
Train: 12 [1905/1906 (100%)]  Loss: 3.075 (2.99)  Time: 1.495s,  449.60/s  (1.514s,  443.76/s)  LR: 1.524e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.664 (3.664)  Loss:  0.5571 (0.5571)  Acc@1: 91.8945 (91.8945)  Acc@5: 97.9492 (97.9492)
Test: [  48/48]  Time: 0.773 (0.868)  Loss:  0.6426 (1.0030)  Acc@1: 87.7359 (79.3920)  Acc@5: 97.6415 (94.9460)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-7.pth.tar', 79.5080000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-10.pth.tar', 79.41400010253906)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-11.pth.tar', 79.40799995117187)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-8.pth.tar', 79.39600002685548)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-12.pth.tar', 79.39200010253906)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-9.pth.tar', 79.39000005126952)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-6.pth.tar', 79.384000078125)

Train: 13 [   0/1906 (  0%)]  Loss: 2.881 (2.88)  Time: 2.912s,  230.74/s  (2.912s,  230.74/s)  LR: 1.498e-06  Data: 1.326 (1.326)
Train: 13 [  50/1906 (  3%)]  Loss: 2.765 (2.82)  Time: 1.516s,  443.22/s  (1.561s,  430.45/s)  LR: 1.498e-06  Data: 0.013 (0.040)
Train: 13 [ 100/1906 (  5%)]  Loss: 2.976 (2.87)  Time: 1.508s,  445.61/s  (1.538s,  437.03/s)  LR: 1.498e-06  Data: 0.014 (0.027)
Train: 13 [ 150/1906 (  8%)]  Loss: 3.058 (2.92)  Time: 1.514s,  443.93/s  (1.529s,  439.56/s)  LR: 1.498e-06  Data: 0.013 (0.023)
Train: 13 [ 200/1906 ( 10%)]  Loss: 2.826 (2.90)  Time: 1.511s,  444.65/s  (1.525s,  440.80/s)  LR: 1.498e-06  Data: 0.013 (0.020)
Train: 13 [ 250/1906 ( 13%)]  Loss: 3.108 (2.94)  Time: 1.511s,  444.70/s  (1.523s,  441.12/s)  LR: 1.498e-06  Data: 0.012 (0.019)
Train: 13 [ 300/1906 ( 16%)]  Loss: 2.872 (2.93)  Time: 1.505s,  446.42/s  (1.521s,  441.73/s)  LR: 1.498e-06  Data: 0.013 (0.018)
Train: 13 [ 350/1906 ( 18%)]  Loss: 2.724 (2.90)  Time: 1.540s,  436.40/s  (1.521s,  441.74/s)  LR: 1.498e-06  Data: 0.013 (0.017)
Train: 13 [ 400/1906 ( 21%)]  Loss: 3.181 (2.93)  Time: 1.532s,  438.50/s  (1.523s,  441.31/s)  LR: 1.498e-06  Data: 0.013 (0.017)
Train: 13 [ 450/1906 ( 24%)]  Loss: 2.492 (2.89)  Time: 1.515s,  443.65/s  (1.523s,  441.21/s)  LR: 1.498e-06  Data: 0.014 (0.016)
Train: 13 [ 500/1906 ( 26%)]  Loss: 3.020 (2.90)  Time: 1.510s,  445.06/s  (1.522s,  441.56/s)  LR: 1.498e-06  Data: 0.014 (0.016)
Train: 13 [ 550/1906 ( 29%)]  Loss: 2.980 (2.91)  Time: 1.515s,  443.61/s  (1.521s,  441.84/s)  LR: 1.498e-06  Data: 0.014 (0.016)
Train: 13 [ 600/1906 ( 31%)]  Loss: 2.663 (2.89)  Time: 1.507s,  445.81/s  (1.520s,  442.08/s)  LR: 1.498e-06  Data: 0.014 (0.016)
Train: 13 [ 650/1906 ( 34%)]  Loss: 3.210 (2.91)  Time: 1.509s,  445.41/s  (1.519s,  442.27/s)  LR: 1.498e-06  Data: 0.013 (0.016)
Train: 13 [ 700/1906 ( 37%)]  Loss: 3.082 (2.92)  Time: 1.509s,  445.43/s  (1.519s,  442.44/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [ 750/1906 ( 39%)]  Loss: 3.222 (2.94)  Time: 1.519s,  442.37/s  (1.518s,  442.58/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [ 800/1906 ( 42%)]  Loss: 2.743 (2.93)  Time: 1.518s,  442.71/s  (1.518s,  442.72/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [ 850/1906 ( 45%)]  Loss: 3.277 (2.95)  Time: 1.508s,  445.58/s  (1.517s,  442.85/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [ 900/1906 ( 47%)]  Loss: 3.041 (2.95)  Time: 1.536s,  437.41/s  (1.517s,  442.86/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [ 950/1906 ( 50%)]  Loss: 3.116 (2.96)  Time: 1.533s,  438.33/s  (1.518s,  442.58/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [1000/1906 ( 52%)]  Loss: 2.841 (2.96)  Time: 1.535s,  437.70/s  (1.519s,  442.36/s)  LR: 1.498e-06  Data: 0.014 (0.015)
Train: 13 [1050/1906 ( 55%)]  Loss: 3.248 (2.97)  Time: 1.537s,  437.18/s  (1.520s,  442.16/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [1100/1906 ( 58%)]  Loss: 2.994 (2.97)  Time: 1.510s,  445.08/s  (1.520s,  442.23/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [1150/1906 ( 60%)]  Loss: 2.988 (2.97)  Time: 1.513s,  444.12/s  (1.519s,  442.29/s)  LR: 1.498e-06  Data: 0.014 (0.015)
Train: 13 [1200/1906 ( 63%)]  Loss: 2.622 (2.96)  Time: 1.531s,  438.83/s  (1.519s,  442.37/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [1250/1906 ( 66%)]  Loss: 3.131 (2.96)  Time: 1.515s,  443.50/s  (1.519s,  442.45/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [1300/1906 ( 68%)]  Loss: 3.178 (2.97)  Time: 1.507s,  445.92/s  (1.519s,  442.51/s)  LR: 1.498e-06  Data: 0.013 (0.015)
Train: 13 [1350/1906 ( 71%)]  Loss: 2.930 (2.97)  Time: 1.537s,  437.26/s  (1.519s,  442.45/s)  LR: 1.498e-06  Data: 0.013 (0.014)
Train: 13 [1400/1906 ( 73%)]  Loss: 2.850 (2.97)  Time: 1.507s,  446.06/s  (1.519s,  442.53/s)  LR: 1.498e-06  Data: 0.013 (0.014)
Train: 13 [1450/1906 ( 76%)]  Loss: 3.307 (2.98)  Time: 1.513s,  444.08/s  (1.518s,  442.60/s)  LR: 1.498e-06  Data: 0.014 (0.014)
Train: 13 [1500/1906 ( 79%)]  Loss: 3.234 (2.99)  Time: 1.506s,  446.25/s  (1.518s,  442.68/s)  LR: 1.498e-06  Data: 0.014 (0.014)
Train: 13 [1550/1906 ( 81%)]  Loss: 3.240 (2.99)  Time: 1.511s,  444.74/s  (1.518s,  442.74/s)  LR: 1.498e-06  Data: 0.014 (0.014)
Train: 13 [1600/1906 ( 84%)]  Loss: 2.831 (2.99)  Time: 1.506s,  446.07/s  (1.518s,  442.80/s)  LR: 1.498e-06  Data: 0.014 (0.014)
Train: 13 [1650/1906 ( 87%)]  Loss: 3.005 (2.99)  Time: 1.512s,  444.32/s  (1.517s,  442.87/s)  LR: 1.498e-06  Data: 0.013 (0.014)
Train: 13 [1700/1906 ( 89%)]  Loss: 2.973 (2.99)  Time: 1.508s,  445.48/s  (1.517s,  442.90/s)  LR: 1.498e-06  Data: 0.013 (0.014)
Train: 13 [1750/1906 ( 92%)]  Loss: 3.293 (3.00)  Time: 1.513s,  444.28/s  (1.517s,  442.90/s)  LR: 1.498e-06  Data: 0.013 (0.014)
Train: 13 [1800/1906 ( 94%)]  Loss: 2.985 (3.00)  Time: 1.536s,  437.62/s  (1.517s,  442.84/s)  LR: 1.498e-06  Data: 0.013 (0.014)
Train: 13 [1850/1906 ( 97%)]  Loss: 3.080 (3.00)  Time: 1.515s,  443.71/s  (1.518s,  442.71/s)  LR: 1.498e-06  Data: 0.013 (0.014)
Train: 13 [1900/1906 (100%)]  Loss: 3.185 (3.00)  Time: 1.510s,  445.17/s  (1.518s,  442.64/s)  LR: 1.498e-06  Data: 0.013 (0.014)
Train: 13 [1905/1906 (100%)]  Loss: 3.096 (3.01)  Time: 1.498s,  448.58/s  (1.518s,  442.65/s)  LR: 1.498e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.550 (3.550)  Loss:  0.6060 (0.6060)  Acc@1: 91.9922 (91.9922)  Acc@5: 98.2422 (98.2422)
Test: [  48/48]  Time: 0.772 (0.866)  Loss:  0.6914 (1.0492)  Acc@1: 87.3821 (79.2600)  Acc@5: 97.6415 (94.9280)
Train: 14 [   0/1906 (  0%)]  Loss: 2.635 (2.64)  Time: 3.030s,  221.76/s  (3.030s,  221.76/s)  LR: 1.470e-06  Data: 1.586 (1.586)
Train: 14 [  50/1906 (  3%)]  Loss: 2.868 (2.75)  Time: 1.532s,  438.60/s  (1.561s,  430.63/s)  LR: 1.470e-06  Data: 0.014 (0.044)
Train: 14 [ 100/1906 (  5%)]  Loss: 3.158 (2.89)  Time: 1.511s,  444.76/s  (1.541s,  436.05/s)  LR: 1.470e-06  Data: 0.013 (0.029)
Train: 14 [ 150/1906 (  8%)]  Loss: 2.897 (2.89)  Time: 1.510s,  445.04/s  (1.533s,  438.34/s)  LR: 1.470e-06  Data: 0.013 (0.024)
Train: 14 [ 200/1906 ( 10%)]  Loss: 2.987 (2.91)  Time: 1.513s,  444.24/s  (1.529s,  439.54/s)  LR: 1.470e-06  Data: 0.013 (0.021)
Train: 14 [ 250/1906 ( 13%)]  Loss: 3.215 (2.96)  Time: 1.512s,  444.37/s  (1.525s,  440.54/s)  LR: 1.470e-06  Data: 0.013 (0.020)
Train: 14 [ 300/1906 ( 16%)]  Loss: 3.209 (3.00)  Time: 1.513s,  444.01/s  (1.524s,  440.98/s)  LR: 1.470e-06  Data: 0.013 (0.019)
Train: 14 [ 350/1906 ( 18%)]  Loss: 2.923 (2.99)  Time: 1.510s,  444.99/s  (1.522s,  441.50/s)  LR: 1.470e-06  Data: 0.013 (0.018)
Train: 14 [ 400/1906 ( 21%)]  Loss: 2.915 (2.98)  Time: 1.509s,  445.24/s  (1.521s,  441.88/s)  LR: 1.470e-06  Data: 0.013 (0.017)
Train: 14 [ 450/1906 ( 24%)]  Loss: 2.942 (2.97)  Time: 1.511s,  444.67/s  (1.520s,  442.02/s)  LR: 1.470e-06  Data: 0.013 (0.017)
Train: 14 [ 500/1906 ( 26%)]  Loss: 2.489 (2.93)  Time: 1.510s,  444.91/s  (1.519s,  442.27/s)  LR: 1.470e-06  Data: 0.014 (0.017)
Train: 14 [ 550/1906 ( 29%)]  Loss: 2.696 (2.91)  Time: 1.535s,  437.90/s  (1.520s,  441.96/s)  LR: 1.470e-06  Data: 0.013 (0.016)
Train: 14 [ 600/1906 ( 31%)]  Loss: 2.853 (2.91)  Time: 1.510s,  444.90/s  (1.520s,  442.00/s)  LR: 1.470e-06  Data: 0.013 (0.016)
Train: 14 [ 650/1906 ( 34%)]  Loss: 3.127 (2.92)  Time: 1.533s,  438.50/s  (1.521s,  441.95/s)  LR: 1.470e-06  Data: 0.013 (0.016)
Train: 14 [ 700/1906 ( 37%)]  Loss: 2.701 (2.91)  Time: 1.537s,  437.33/s  (1.521s,  441.74/s)  LR: 1.470e-06  Data: 0.013 (0.016)
Train: 14 [ 750/1906 ( 39%)]  Loss: 3.064 (2.92)  Time: 1.536s,  437.44/s  (1.522s,  441.54/s)  LR: 1.470e-06  Data: 0.014 (0.016)
Train: 14 [ 800/1906 ( 42%)]  Loss: 2.915 (2.92)  Time: 1.531s,  439.04/s  (1.523s,  441.38/s)  LR: 1.470e-06  Data: 0.013 (0.015)
Train: 14 [ 850/1906 ( 45%)]  Loss: 2.982 (2.92)  Time: 1.511s,  444.74/s  (1.522s,  441.40/s)  LR: 1.470e-06  Data: 0.013 (0.015)
Train: 14 [ 900/1906 ( 47%)]  Loss: 3.291 (2.94)  Time: 1.533s,  438.32/s  (1.522s,  441.46/s)  LR: 1.470e-06  Data: 0.013 (0.015)
Train: 14 [ 950/1906 ( 50%)]  Loss: 2.789 (2.93)  Time: 1.537s,  437.15/s  (1.523s,  441.27/s)  LR: 1.470e-06  Data: 0.014 (0.015)
Train: 14 [1000/1906 ( 52%)]  Loss: 2.890 (2.93)  Time: 1.538s,  436.98/s  (1.523s,  441.10/s)  LR: 1.470e-06  Data: 0.013 (0.015)
Train: 14 [1050/1906 ( 55%)]  Loss: 3.182 (2.94)  Time: 1.511s,  444.73/s  (1.523s,  441.15/s)  LR: 1.470e-06  Data: 0.013 (0.015)
Train: 14 [1100/1906 ( 58%)]  Loss: 3.000 (2.94)  Time: 1.514s,  443.71/s  (1.523s,  441.31/s)  LR: 1.470e-06  Data: 0.014 (0.015)
Train: 14 [1150/1906 ( 60%)]  Loss: 2.991 (2.95)  Time: 1.512s,  444.58/s  (1.523s,  441.36/s)  LR: 1.470e-06  Data: 0.014 (0.015)
Train: 14 [1200/1906 ( 63%)]  Loss: 2.757 (2.94)  Time: 1.517s,  442.91/s  (1.522s,  441.46/s)  LR: 1.470e-06  Data: 0.013 (0.015)
Train: 14 [1250/1906 ( 66%)]  Loss: 3.187 (2.95)  Time: 1.512s,  444.39/s  (1.522s,  441.58/s)  LR: 1.470e-06  Data: 0.014 (0.015)
Train: 14 [1300/1906 ( 68%)]  Loss: 3.153 (2.96)  Time: 1.513s,  444.02/s  (1.522s,  441.63/s)  LR: 1.470e-06  Data: 0.013 (0.015)
Train: 14 [1350/1906 ( 71%)]  Loss: 2.968 (2.96)  Time: 1.512s,  444.56/s  (1.521s,  441.70/s)  LR: 1.470e-06  Data: 0.014 (0.015)
Train: 14 [1400/1906 ( 73%)]  Loss: 3.315 (2.97)  Time: 1.511s,  444.68/s  (1.521s,  441.80/s)  LR: 1.470e-06  Data: 0.013 (0.015)
Train: 14 [1450/1906 ( 76%)]  Loss: 2.640 (2.96)  Time: 1.512s,  444.54/s  (1.521s,  441.89/s)  LR: 1.470e-06  Data: 0.013 (0.015)
Train: 14 [1500/1906 ( 79%)]  Loss: 3.009 (2.96)  Time: 1.513s,  444.23/s  (1.520s,  441.99/s)  LR: 1.470e-06  Data: 0.014 (0.015)
Train: 14 [1550/1906 ( 81%)]  Loss: 2.774 (2.95)  Time: 1.512s,  444.54/s  (1.520s,  442.07/s)  LR: 1.470e-06  Data: 0.014 (0.015)
Train: 14 [1600/1906 ( 84%)]  Loss: 3.028 (2.96)  Time: 1.514s,  443.84/s  (1.520s,  442.15/s)  LR: 1.470e-06  Data: 0.014 (0.014)
Train: 14 [1650/1906 ( 87%)]  Loss: 2.897 (2.95)  Time: 1.536s,  437.63/s  (1.520s,  442.18/s)  LR: 1.470e-06  Data: 0.014 (0.014)
Train: 14 [1700/1906 ( 89%)]  Loss: 3.080 (2.96)  Time: 1.537s,  437.25/s  (1.520s,  442.05/s)  LR: 1.470e-06  Data: 0.014 (0.014)
Train: 14 [1750/1906 ( 92%)]  Loss: 3.057 (2.96)  Time: 1.512s,  444.45/s  (1.520s,  442.11/s)  LR: 1.470e-06  Data: 0.014 (0.014)
Train: 14 [1800/1906 ( 94%)]  Loss: 2.765 (2.96)  Time: 1.510s,  444.96/s  (1.520s,  442.18/s)  LR: 1.470e-06  Data: 0.013 (0.014)
Train: 14 [1850/1906 ( 97%)]  Loss: 2.943 (2.96)  Time: 1.515s,  443.57/s  (1.520s,  442.16/s)  LR: 1.470e-06  Data: 0.014 (0.014)
Train: 14 [1900/1906 (100%)]  Loss: 2.804 (2.95)  Time: 1.514s,  443.98/s  (1.520s,  442.21/s)  LR: 1.470e-06  Data: 0.013 (0.014)
Train: 14 [1905/1906 (100%)]  Loss: 2.984 (2.95)  Time: 1.499s,  448.34/s  (1.520s,  442.22/s)  LR: 1.470e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.574 (3.574)  Loss:  0.5005 (0.5005)  Acc@1: 91.8945 (91.8945)  Acc@5: 98.0469 (98.0469)
Test: [  48/48]  Time: 0.772 (0.866)  Loss:  0.5996 (0.9505)  Acc@1: 87.0283 (79.4360)  Acc@5: 97.7594 (94.9840)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-7.pth.tar', 79.5080000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-14.pth.tar', 79.43600005371094)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-10.pth.tar', 79.41400010253906)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-11.pth.tar', 79.40799995117187)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-8.pth.tar', 79.39600002685548)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-12.pth.tar', 79.39200010253906)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-9.pth.tar', 79.39000005126952)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-3.pth.tar', 79.38600010498047)

Train: 15 [   0/1906 (  0%)]  Loss: 3.129 (3.13)  Time: 2.950s,  227.82/s  (2.950s,  227.82/s)  LR: 1.441e-06  Data: 1.397 (1.397)
Train: 15 [  50/1906 (  3%)]  Loss: 2.711 (2.92)  Time: 1.508s,  445.54/s  (1.543s,  435.55/s)  LR: 1.441e-06  Data: 0.013 (0.041)
Train: 15 [ 100/1906 (  5%)]  Loss: 3.373 (3.07)  Time: 1.514s,  443.73/s  (1.527s,  439.95/s)  LR: 1.441e-06  Data: 0.013 (0.027)
Train: 15 [ 150/1906 (  8%)]  Loss: 2.704 (2.98)  Time: 1.510s,  445.15/s  (1.523s,  441.33/s)  LR: 1.441e-06  Data: 0.014 (0.023)
Train: 15 [ 200/1906 ( 10%)]  Loss: 3.023 (2.99)  Time: 1.538s,  436.98/s  (1.524s,  440.95/s)  LR: 1.441e-06  Data: 0.013 (0.020)
Train: 15 [ 250/1906 ( 13%)]  Loss: 3.337 (3.05)  Time: 1.507s,  445.90/s  (1.525s,  440.72/s)  LR: 1.441e-06  Data: 0.013 (0.019)
Train: 15 [ 300/1906 ( 16%)]  Loss: 2.892 (3.02)  Time: 1.513s,  444.09/s  (1.523s,  441.13/s)  LR: 1.441e-06  Data: 0.014 (0.018)
Train: 15 [ 350/1906 ( 18%)]  Loss: 3.208 (3.05)  Time: 1.509s,  445.18/s  (1.522s,  441.52/s)  LR: 1.441e-06  Data: 0.013 (0.018)
Train: 15 [ 400/1906 ( 21%)]  Loss: 2.772 (3.02)  Time: 1.539s,  436.61/s  (1.522s,  441.67/s)  LR: 1.441e-06  Data: 0.012 (0.017)
Train: 15 [ 450/1906 ( 24%)]  Loss: 3.044 (3.02)  Time: 1.534s,  438.01/s  (1.523s,  441.29/s)  LR: 1.441e-06  Data: 0.013 (0.017)
Train: 15 [ 500/1906 ( 26%)]  Loss: 2.961 (3.01)  Time: 1.514s,  443.96/s  (1.522s,  441.62/s)  LR: 1.441e-06  Data: 0.014 (0.016)
Train: 15 [ 550/1906 ( 29%)]  Loss: 3.266 (3.04)  Time: 1.509s,  445.39/s  (1.522s,  441.61/s)  LR: 1.441e-06  Data: 0.014 (0.016)
Train: 15 [ 600/1906 ( 31%)]  Loss: 2.722 (3.01)  Time: 1.512s,  444.54/s  (1.521s,  441.73/s)  LR: 1.441e-06  Data: 0.013 (0.016)
Train: 15 [ 650/1906 ( 34%)]  Loss: 3.281 (3.03)  Time: 1.535s,  437.72/s  (1.522s,  441.42/s)  LR: 1.441e-06  Data: 0.013 (0.016)
Train: 15 [ 700/1906 ( 37%)]  Loss: 3.528 (3.06)  Time: 1.519s,  442.35/s  (1.523s,  441.23/s)  LR: 1.441e-06  Data: 0.014 (0.016)
Train: 15 [ 750/1906 ( 39%)]  Loss: 2.966 (3.06)  Time: 1.538s,  436.92/s  (1.523s,  441.35/s)  LR: 1.441e-06  Data: 0.013 (0.015)
Train: 15 [ 800/1906 ( 42%)]  Loss: 2.978 (3.05)  Time: 1.513s,  444.09/s  (1.522s,  441.53/s)  LR: 1.441e-06  Data: 0.014 (0.015)
Train: 15 [ 850/1906 ( 45%)]  Loss: 2.983 (3.05)  Time: 1.511s,  444.62/s  (1.521s,  441.73/s)  LR: 1.441e-06  Data: 0.013 (0.015)
Train: 15 [ 900/1906 ( 47%)]  Loss: 2.841 (3.04)  Time: 1.513s,  444.09/s  (1.521s,  441.88/s)  LR: 1.441e-06  Data: 0.014 (0.015)
Train: 15 [ 950/1906 ( 50%)]  Loss: 3.292 (3.05)  Time: 1.510s,  445.15/s  (1.521s,  441.72/s)  LR: 1.441e-06  Data: 0.013 (0.015)
Train: 15 [1000/1906 ( 52%)]  Loss: 3.655 (3.08)  Time: 1.512s,  444.42/s  (1.521s,  441.87/s)  LR: 1.441e-06  Data: 0.014 (0.015)
Train: 15 [1050/1906 ( 55%)]  Loss: 3.026 (3.08)  Time: 1.506s,  446.18/s  (1.520s,  442.00/s)  LR: 1.441e-06  Data: 0.014 (0.015)
Train: 15 [1100/1906 ( 58%)]  Loss: 3.150 (3.08)  Time: 1.514s,  443.94/s  (1.520s,  442.11/s)  LR: 1.441e-06  Data: 0.013 (0.015)
Train: 15 [1150/1906 ( 60%)]  Loss: 3.043 (3.08)  Time: 1.507s,  445.80/s  (1.520s,  442.23/s)  LR: 1.441e-06  Data: 0.013 (0.015)
Train: 15 [1200/1906 ( 63%)]  Loss: 3.169 (3.08)  Time: 1.538s,  436.89/s  (1.520s,  442.13/s)  LR: 1.441e-06  Data: 0.013 (0.015)
Train: 15 [1250/1906 ( 66%)]  Loss: 3.301 (3.09)  Time: 1.512s,  444.46/s  (1.520s,  441.98/s)  LR: 1.441e-06  Data: 0.014 (0.015)
Train: 15 [1300/1906 ( 68%)]  Loss: 3.166 (3.09)  Time: 1.510s,  444.92/s  (1.520s,  442.08/s)  LR: 1.441e-06  Data: 0.014 (0.015)
Train: 15 [1350/1906 ( 71%)]  Loss: 2.991 (3.09)  Time: 1.521s,  441.81/s  (1.520s,  442.14/s)  LR: 1.441e-06  Data: 0.014 (0.015)
Train: 15 [1400/1906 ( 73%)]  Loss: 2.738 (3.08)  Time: 1.514s,  443.87/s  (1.520s,  442.23/s)  LR: 1.441e-06  Data: 0.014 (0.015)
Train: 15 [1450/1906 ( 76%)]  Loss: 2.707 (3.07)  Time: 1.509s,  445.25/s  (1.520s,  442.24/s)  LR: 1.441e-06  Data: 0.013 (0.015)
Train: 15 [1500/1906 ( 79%)]  Loss: 3.036 (3.06)  Time: 1.514s,  443.95/s  (1.519s,  442.25/s)  LR: 1.441e-06  Data: 0.013 (0.015)
Train: 15 [1550/1906 ( 81%)]  Loss: 3.091 (3.07)  Time: 1.510s,  445.08/s  (1.519s,  442.33/s)  LR: 1.441e-06  Data: 0.013 (0.014)
Train: 15 [1600/1906 ( 84%)]  Loss: 2.961 (3.06)  Time: 1.542s,  435.86/s  (1.519s,  442.35/s)  LR: 1.441e-06  Data: 0.013 (0.014)
Train: 15 [1650/1906 ( 87%)]  Loss: 2.966 (3.06)  Time: 1.525s,  440.62/s  (1.520s,  442.25/s)  LR: 1.441e-06  Data: 0.013 (0.014)
Train: 15 [1700/1906 ( 89%)]  Loss: 2.833 (3.05)  Time: 1.536s,  437.45/s  (1.520s,  442.11/s)  LR: 1.441e-06  Data: 0.013 (0.014)
Train: 15 [1750/1906 ( 92%)]  Loss: 2.967 (3.05)  Time: 1.532s,  438.51/s  (1.520s,  441.99/s)  LR: 1.441e-06  Data: 0.013 (0.014)
Train: 15 [1800/1906 ( 94%)]  Loss: 3.014 (3.05)  Time: 1.512s,  444.41/s  (1.520s,  442.00/s)  LR: 1.441e-06  Data: 0.014 (0.014)
Train: 15 [1850/1906 ( 97%)]  Loss: 3.057 (3.05)  Time: 1.505s,  446.39/s  (1.520s,  442.07/s)  LR: 1.441e-06  Data: 0.013 (0.014)
Train: 15 [1900/1906 (100%)]  Loss: 3.143 (3.05)  Time: 1.511s,  444.86/s  (1.520s,  442.13/s)  LR: 1.441e-06  Data: 0.013 (0.014)
Train: 15 [1905/1906 (100%)]  Loss: 3.023 (3.05)  Time: 1.500s,  447.99/s  (1.520s,  442.14/s)  LR: 1.441e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.558 (3.558)  Loss:  0.5142 (0.5142)  Acc@1: 91.8945 (91.8945)  Acc@5: 98.1445 (98.1445)
Test: [  48/48]  Time: 0.773 (0.866)  Loss:  0.6094 (0.9600)  Acc@1: 87.1462 (79.3500)  Acc@5: 97.6415 (95.0060)
Train: 16 [   0/1906 (  0%)]  Loss: 2.684 (2.68)  Time: 2.922s,  229.97/s  (2.922s,  229.97/s)  LR: 1.410e-06  Data: 1.368 (1.368)
Train: 16 [  50/1906 (  3%)]  Loss: 2.943 (2.81)  Time: 1.516s,  443.35/s  (1.540s,  436.25/s)  LR: 1.410e-06  Data: 0.014 (0.040)
Train: 16 [ 100/1906 (  5%)]  Loss: 3.206 (2.94)  Time: 1.535s,  437.70/s  (1.527s,  440.19/s)  LR: 1.410e-06  Data: 0.014 (0.027)
Train: 16 [ 150/1906 (  8%)]  Loss: 2.844 (2.92)  Time: 1.509s,  445.39/s  (1.523s,  441.35/s)  LR: 1.410e-06  Data: 0.014 (0.023)
Train: 16 [ 200/1906 ( 10%)]  Loss: 2.860 (2.91)  Time: 1.511s,  444.84/s  (1.526s,  440.44/s)  LR: 1.410e-06  Data: 0.013 (0.020)
Train: 16 [ 250/1906 ( 13%)]  Loss: 2.775 (2.89)  Time: 1.540s,  436.30/s  (1.524s,  441.05/s)  LR: 1.410e-06  Data: 0.013 (0.019)
Train: 16 [ 300/1906 ( 16%)]  Loss: 2.831 (2.88)  Time: 1.509s,  445.32/s  (1.524s,  440.95/s)  LR: 1.410e-06  Data: 0.013 (0.018)
Train: 16 [ 350/1906 ( 18%)]  Loss: 3.131 (2.91)  Time: 1.538s,  436.93/s  (1.524s,  441.04/s)  LR: 1.410e-06  Data: 0.013 (0.017)
Train: 16 [ 400/1906 ( 21%)]  Loss: 2.746 (2.89)  Time: 1.537s,  437.22/s  (1.525s,  440.74/s)  LR: 1.410e-06  Data: 0.013 (0.017)
Train: 16 [ 450/1906 ( 24%)]  Loss: 3.287 (2.93)  Time: 1.540s,  436.29/s  (1.526s,  440.38/s)  LR: 1.410e-06  Data: 0.014 (0.017)
Train: 16 [ 500/1906 ( 26%)]  Loss: 2.691 (2.91)  Time: 1.534s,  438.11/s  (1.525s,  440.60/s)  LR: 1.410e-06  Data: 0.013 (0.016)
Train: 16 [ 550/1906 ( 29%)]  Loss: 3.357 (2.95)  Time: 1.538s,  436.83/s  (1.526s,  440.33/s)  LR: 1.410e-06  Data: 0.014 (0.016)
Train: 16 [ 600/1906 ( 31%)]  Loss: 2.750 (2.93)  Time: 1.512s,  444.52/s  (1.526s,  440.36/s)  LR: 1.410e-06  Data: 0.013 (0.016)
Train: 16 [ 650/1906 ( 34%)]  Loss: 3.174 (2.95)  Time: 1.535s,  437.65/s  (1.525s,  440.66/s)  LR: 1.410e-06  Data: 0.013 (0.016)
Train: 16 [ 700/1906 ( 37%)]  Loss: 3.039 (2.95)  Time: 1.514s,  443.87/s  (1.525s,  440.67/s)  LR: 1.410e-06  Data: 0.013 (0.016)
Train: 16 [ 750/1906 ( 39%)]  Loss: 3.400 (2.98)  Time: 1.541s,  435.99/s  (1.524s,  440.88/s)  LR: 1.410e-06  Data: 0.020 (0.015)
Train: 16 [ 800/1906 ( 42%)]  Loss: 3.257 (3.00)  Time: 1.540s,  436.47/s  (1.525s,  440.62/s)  LR: 1.410e-06  Data: 0.014 (0.015)
Train: 16 [ 850/1906 ( 45%)]  Loss: 3.308 (3.02)  Time: 1.534s,  438.08/s  (1.525s,  440.64/s)  LR: 1.410e-06  Data: 0.013 (0.015)
Train: 16 [ 900/1906 ( 47%)]  Loss: 3.153 (3.02)  Time: 1.537s,  437.16/s  (1.526s,  440.45/s)  LR: 1.410e-06  Data: 0.013 (0.015)
Train: 16 [ 950/1906 ( 50%)]  Loss: 2.598 (3.00)  Time: 1.536s,  437.44/s  (1.526s,  440.29/s)  LR: 1.410e-06  Data: 0.014 (0.015)
Train: 16 [1000/1906 ( 52%)]  Loss: 2.941 (3.00)  Time: 1.537s,  437.24/s  (1.527s,  440.14/s)  LR: 1.410e-06  Data: 0.013 (0.015)
Train: 16 [1050/1906 ( 55%)]  Loss: 2.889 (2.99)  Time: 1.535s,  437.72/s  (1.527s,  440.01/s)  LR: 1.410e-06  Data: 0.013 (0.015)
Train: 16 [1100/1906 ( 58%)]  Loss: 2.961 (2.99)  Time: 1.509s,  445.27/s  (1.527s,  440.11/s)  LR: 1.410e-06  Data: 0.013 (0.015)
Train: 16 [1150/1906 ( 60%)]  Loss: 3.099 (3.00)  Time: 1.512s,  444.33/s  (1.526s,  440.30/s)  LR: 1.410e-06  Data: 0.014 (0.015)
Train: 16 [1200/1906 ( 63%)]  Loss: 2.729 (2.99)  Time: 1.517s,  442.98/s  (1.526s,  440.28/s)  LR: 1.410e-06  Data: 0.013 (0.015)
Train: 16 [1250/1906 ( 66%)]  Loss: 3.564 (3.01)  Time: 1.529s,  439.60/s  (1.526s,  440.33/s)  LR: 1.410e-06  Data: 0.014 (0.015)
Train: 16 [1300/1906 ( 68%)]  Loss: 2.731 (3.00)  Time: 1.529s,  439.51/s  (1.526s,  440.28/s)  LR: 1.410e-06  Data: 0.014 (0.015)
Train: 16 [1350/1906 ( 71%)]  Loss: 2.855 (2.99)  Time: 1.531s,  438.96/s  (1.526s,  440.23/s)  LR: 1.410e-06  Data: 0.014 (0.015)
Train: 16 [1400/1906 ( 73%)]  Loss: 3.209 (3.00)  Time: 1.510s,  444.99/s  (1.526s,  440.33/s)  LR: 1.410e-06  Data: 0.013 (0.015)
Train: 16 [1450/1906 ( 76%)]  Loss: 3.291 (3.01)  Time: 1.512s,  444.53/s  (1.526s,  440.47/s)  LR: 1.410e-06  Data: 0.014 (0.015)
Train: 16 [1500/1906 ( 79%)]  Loss: 3.081 (3.01)  Time: 1.509s,  445.36/s  (1.526s,  440.36/s)  LR: 1.410e-06  Data: 0.013 (0.015)
Train: 16 [1550/1906 ( 81%)]  Loss: 2.884 (3.01)  Time: 1.537s,  437.09/s  (1.526s,  440.43/s)  LR: 1.410e-06  Data: 0.014 (0.015)
Train: 16 [1600/1906 ( 84%)]  Loss: 3.483 (3.02)  Time: 1.528s,  439.82/s  (1.526s,  440.43/s)  LR: 1.410e-06  Data: 0.013 (0.014)
Train: 16 [1650/1906 ( 87%)]  Loss: 2.573 (3.01)  Time: 1.513s,  444.06/s  (1.525s,  440.52/s)  LR: 1.410e-06  Data: 0.013 (0.014)
Train: 16 [1700/1906 ( 89%)]  Loss: 2.434 (2.99)  Time: 1.515s,  443.59/s  (1.525s,  440.55/s)  LR: 1.410e-06  Data: 0.014 (0.014)
Train: 16 [1750/1906 ( 92%)]  Loss: 3.074 (3.00)  Time: 1.511s,  444.76/s  (1.525s,  440.62/s)  LR: 1.410e-06  Data: 0.014 (0.014)
Train: 16 [1800/1906 ( 94%)]  Loss: 2.565 (2.98)  Time: 1.513s,  444.27/s  (1.525s,  440.72/s)  LR: 1.410e-06  Data: 0.014 (0.014)
Train: 16 [1850/1906 ( 97%)]  Loss: 3.204 (2.99)  Time: 1.535s,  437.92/s  (1.524s,  440.81/s)  LR: 1.410e-06  Data: 0.014 (0.014)
Train: 16 [1900/1906 (100%)]  Loss: 3.144 (2.99)  Time: 1.513s,  444.02/s  (1.524s,  440.81/s)  LR: 1.410e-06  Data: 0.013 (0.014)
Train: 16 [1905/1906 (100%)]  Loss: 2.644 (2.98)  Time: 1.501s,  447.74/s  (1.524s,  440.82/s)  LR: 1.410e-06  Data: 0.000 (0.014)
Distributing BatchNorm running means and vars
Test: [   0/48]  Time: 3.529 (3.529)  Loss:  0.5273 (0.5273)  Acc@1: 91.9922 (91.9922)  Acc@5: 98.2422 (98.2422)
Test: [  48/48]  Time: 0.774 (0.866)  Loss:  0.6260 (0.9778)  Acc@1: 87.6179 (79.3880)  Acc@5: 97.7594 (94.9760)
Current checkpoints:
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-7.pth.tar', 79.5080000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-14.pth.tar', 79.43600005371094)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-4.pth.tar', 79.42000005126953)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-10.pth.tar', 79.41400010253906)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-11.pth.tar', 79.40799995117187)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-0.pth.tar', 79.4000000805664)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-8.pth.tar', 79.39600002685548)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-12.pth.tar', 79.39200010253906)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-9.pth.tar', 79.39000005126952)
 ('./output/train/20230407-221234-skanet_small-256/checkpoint-16.pth.tar', 79.38800005126953)

Train: 17 [   0/1906 (  0%)]  Loss: 2.486 (2.49)  Time: 2.910s,  230.90/s  (2.910s,  230.90/s)  LR: 1.378e-06  Data: 1.350 (1.350)
Train: 17 [  50/1906 (  3%)]  Loss: 3.224 (2.86)  Time: 1.535s,  437.64/s  (1.546s,  434.65/s)  LR: 1.378e-06  Data: 0.014 (0.040)
Train: 17 [ 100/1906 (  5%)]  Loss: 2.917 (2.88)  Time: 1.510s,  445.05/s  (1.530s,  439.08/s)  LR: 1.378e-06  Data: 0.014 (0.027)
Train: 17 [ 150/1906 (  8%)]  Loss: 2.842 (2.87)  Time: 1.536s,  437.54/s  (1.527s,  439.94/s)  LR: 1.378e-06  Data: 0.013 (0.022)
Train: 17 [ 200/1906 ( 10%)]  Loss: 3.386 (2.97)  Time: 1.511s,  444.64/s  (1.527s,  440.19/s)  LR: 1.378e-06  Data: 0.013 (0.020)
Train: 17 [ 250/1906 ( 13%)]  Loss: 3.464 (3.05)  Time: 1.509s,  445.45/s  (1.523s,  441.15/s)  LR: 1.378e-06  Data: 0.014 (0.019)
Train: 17 [ 300/1906 ( 16%)]  Loss: 3.197 (3.07)  Time: 1.512s,  444.59/s  (1.523s,  441.26/s)  LR: 1.378e-06  Data: 0.013 (0.018)
Train: 17 [ 350/1906 ( 18%)]  Loss: 3.075 (3.07)  Time: 1.531s,  438.97/s  (1.522s,  441.48/s)  LR: 1.378e-06  Data: 0.013 (0.017)
Train: 17 [ 400/1906 ( 21%)]  Loss: 3.259 (3.09)  Time: 1.509s,  445.36/s  (1.522s,  441.59/s)  LR: 1.378e-06  Data: 0.014 (0.017)
Train: 17 [ 450/1906 ( 24%)]  Loss: 2.497 (3.03)  Time: 1.533s,  438.23/s  (1.522s,  441.46/s)  LR: 1.378e-06  Data: 0.014 (0.016)
Train: 17 [ 500/1906 ( 26%)]  Loss: 2.979 (3.03)  Time: 1.512s,  444.47/s  (1.521s,  441.75/s)  LR: 1.378e-06  Data: 0.014 (0.016)
Train: 17 [ 550/1906 ( 29%)]  Loss: 2.875 (3.02)  Time: 1.507s,  445.84/s  (1.521s,  441.86/s)  LR: 1.378e-06  Data: 0.014 (0.016)
Train: 17 [ 600/1906 ( 31%)]  Loss: 3.217 (3.03)  Time: 1.515s,  443.61/s  (1.521s,  441.95/s)  LR: 1.378e-06  Data: 0.013 (0.016)
Train: 17 [ 650/1906 ( 34%)]  Loss: 3.222 (3.05)  Time: 1.536s,  437.54/s  (1.521s,  441.71/s)  LR: 1.378e-06  Data: 0.014 (0.016)
Train: 17 [ 700/1906 ( 37%)]  Loss: 3.386 (3.07)  Time: 1.538s,  436.96/s  (1.522s,  441.46/s)  LR: 1.378e-06  Data: 0.013 (0.015)
Train: 17 [ 750/1906 ( 39%)]  Loss: 2.898 (3.06)  Time: 1.533s,  438.28/s  (1.523s,  441.21/s)  LR: 1.378e-06  Data: 0.013 (0.015)
Train: 17 [ 800/1906 ( 42%)]  Loss: 3.214 (3.07)  Time: 1.535s,  437.91/s  (1.524s,  441.00/s)  LR: 1.378e-06  Data: 0.014 (0.015)
Train: 17 [ 850/1906 ( 45%)]  Loss: 2.939 (3.06)  Time: 1.534s,  438.01/s  (1.524s,  440.82/s)  LR: 1.378e-06  Data: 0.014 (0.015)
Train: 17 [ 900/1906 ( 47%)]  Loss: 3.082 (3.06)  Time: 1.539s,  436.61/s  (1.524s,  441.03/s)  LR: 1.378e-06  Data: 0.014 (0.015)
Train: 17 [ 950/1906 ( 50%)]  Loss: 2.886 (3.05)  Time: 1.512s,  444.58/s  (1.523s,  441.14/s)  LR: 1.378e-06  Data: 0.013 (0.015)
Train: 17 [1000/1906 ( 52%)]  Loss: 2.768 (3.04)  Time: 1.514s,  443.78/s  (1.523s,  441.25/s)  LR: 1.378e-06  Data: 0.013 (0.015)
Train: 17 [1050/1906 ( 55%)]  Loss: 3.340 (3.05)  Time: 1.507s,  446.03/s  (1.522s,  441.42/s)  LR: 1.378e-06  Data: 0.014 (0.015)
Train: 17 [1100/1906 ( 58%)]  Loss: 2.830 (3.04)  Time: 1.513s,  444.07/s  (1.522s,  441.56/s)  LR: 1.378e-06  Data: 0.013 (0.015)
Train: 17 [1150/1906 ( 60%)]  Loss: 2.562 (3.02)  Time: 1.508s,  445.53/s  (1.521s,  441.69/s)  LR: 1.378e-06  Data: 0.014 (0.015)
Train: 17 [1200/1906 ( 63%)]  Loss: 3.097 (3.03)  Time: 1.514s,  443.98/s  (1.521s,  441.82/s)  LR: 1.378e-06  Data: 0.013 (0.015)
Traceback (most recent call last):
  File "/media/user/clp/annconda3/envs/pytorch/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/media/user/clp/annconda3/envs/pytorch/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/media/user/clp/annconda3/envs/pytorch/lib/python3.7/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/media/user/clp/annconda3/envs/pytorch/lib/python3.7/site-packages/torch/distributed/launch.py", line 256, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/media/user/clp/annconda3/envs/pytorch/bin/python3', '-u', 'train.py', '--local_rank=7', '/media/user/clp/imagenet', '--model', 'skanet_small', '-b', '84', '-vb', '128', '--input-size', '3', '256', '256', '--amp', '--train-interpolation', 'bicubic', '--initial', './output/train/20230401-205524-skanet_small-256/checkpoint-290.pth.tar', '--epochs', '50', '--lr', '1.685e-06', '--min-lr', '5e-7', '--crop-pct', '0.9', '--warmup-epochs', '0']' died with <Signals.SIGKILL: 9>.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
